import os
import json
import asyncio
from typing import TypedDict, Dict, Any, Optional, Annotated
from dotenv import load_dotenv
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langchain_core.messages import HumanMessage
from pydantic import BaseModel, Field
from langchain_openai import ChatOpenAI

# --- ì„œë¹„ìŠ¤ ë° ë…¸ë“œ í´ë˜ìŠ¤ Import ---
from app.services.posture_analyzer import PostureAnalyzer
from app.agents.youtube_agent import graph as youtube_summary_agent
from app.nodes.chatbot_node import ChatbotActionNode
from app.services.exercise_vector_db import ExerciseVectorDB
from data_server import plot_radar_chart

load_dotenv()

# --- 1. ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ---
llm = ChatOpenAI(model="gpt-4o-mini")
posture_analyzer = PostureAnalyzer(model_path="models/yolopose_v1.pt")
chatbot_node = ChatbotActionNode()
vector_db = ExerciseVectorDB()

# --- 2. ê·¸ë˜í”„ ìƒíƒœ (Supervisor íŒ¨í„´ìš©) ---
class SupervisorGraphState(TypedDict):
    # ê° ë…¸ë“œì˜ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë©”ì‹œì§€ í˜•íƒœë¡œ ëˆ„ì í•˜ì—¬ ëŒ€í™”ì˜ íë¦„ì„ ê´€ë¦¬
    messages: Annotated[list, add_messages]
    
    # ë‹¤ìŒìœ¼ë¡œ í˜¸ì¶œí•  ë…¸ë“œì˜ ì´ë¦„ì„ ì €ì¥
    next_agent: str
    
    # ì›ë³¸ ìš”ì²­ ë°ì´í„°
    image_paths: list[str]
    analysis_modes: list[str]
    
    # ì¬ê²€ìƒ‰ íšŸìˆ˜ ì¶”ì 
    search_retries: int
    
    # ë…¸ë“œë³„ ê²°ê³¼ ë°ì´í„°
    pose_analysis_results: list[Dict[str, Any]]
    diagnosis: Dict[str, str]
    recommended_exercise: Dict[str, Any]
    chatbot_result: Dict[str, Any]
    youtube_summary: Optional[Dict[str, Any]]
    comment_count: int
    final_output: Dict[str, Any]
    error: Optional[str]
    
    # ì‚¬ìš©ì ì‘ë‹µ ê´€ë ¨ í•„ë“œ(ëŒ“ê¸€ ìš”ì•½ì—¬ë¶€ ê²°ì •)
    user_response: Optional[str]  # ì‚¬ìš©ìì˜ ì‘ë‹µ
    youtube_thread_id: Optional[str]  # YouTube agentì˜ ìŠ¤ë ˆë“œ ID
    youtube_config: Optional[Dict[str, Any]]  # YouTube agent ì„¤ì •
    
    # ì¬ê²€ìƒ‰ ì‹œ ì œì™¸í•  URL ë¦¬ìŠ¤íŠ¸
    tried_video_urls: list[str]

# --- 3. LangGraph ë…¸ë“œ í•¨ìˆ˜ ì¬ì •ì˜ ---

# ê° ë…¸ë“œëŠ” ì´ì œ 'messages'ì— ìì‹ ì˜ ì‹¤í–‰ ê²°ê³¼ë¥¼ HumanMessage í˜•íƒœë¡œ ì¶”ê°€í•˜ì—¬ ìŠˆí¼ë°”ì´ì €ì—ê²Œ ë³´ê³ í•©ë‹ˆë‹¤.
def analyze_both_poses_node(state: SupervisorGraphState) -> Dict[str, Any]:
    print("[Node 1] ì •ë©´/ì¸¡ë©´ ìì„¸ ë¶„ì„ ì¤‘...")
    results = []
    messages = []
    for image_path, mode in zip(state["image_paths"], state["analysis_modes"]):
        analysis_result = posture_analyzer.analyze_posture(image_path, mode=mode)
        if not analysis_result.get("success") or not analysis_result.get("pose_data"):
            messages.append(HumanMessage(content=f"{mode} ë¶„ì„ ì‹¤íŒ¨"))
            results.append(None)
        else:
            person_analysis = analysis_result["pose_data"][0]
            diagnosis_texts = posture_analyzer.generate_ollama_diagnosis(person_analysis, mode)
            messages.append(HumanMessage(content=f"{mode} ë¶„ì„ ì™„ë£Œ. ì§„ë‹¨: {diagnosis_texts['korean']}"))
            results.append({
                "person_analysis": person_analysis,
                "diagnosis": diagnosis_texts,
                "mode": mode,
                "image_path": image_path
            })
    messages.append(HumanMessage(content="ë‘ ì‚¬ì§„ ë¶„ì„ ì™„ë£Œ"))
    return {
        "pose_analysis_results": results,
        "messages": messages
    }

def plot_avg_radar_chart_node(state: SupervisorGraphState) -> Dict[str, Any]:
    print("[Node X] ë‘ ì‚¬ì§„ score í‰ê·  ë ˆì´ë” ì°¨íŠ¸ ìƒì„± ì¤‘...")
    try:
        results = [r for r in state["pose_analysis_results"] if r is not None]
        keys = ["ëª©score", "ì–´ê¹¨score", "ê³¨ë°˜score", "ì²™ì¶”(ì •ë©´)score", "ì²™ì¶”(ì¸¡ë©´)score"]
        avg_scores = {}
        for key in keys:
            vals = [r["person_analysis"]["scores"].get(key) for r in results if r["person_analysis"]["scores"].get(key) is not None]
            if vals:
                avg_scores[key] = sum(vals) / len(vals)
            else:
                avg_scores[key] = None
        radar_values = {
            "ëª©": avg_scores["ëª©score"],
            "ì–´ê¹¨": avg_scores["ì–´ê¹¨score"],
            "ê³¨ë°˜": avg_scores["ê³¨ë°˜score"],
            "ì²™ì¶”(ì •ë©´)": avg_scores["ì²™ì¶”(ì •ë©´)score"],
            "ì²™ì¶”(ì¸¡ë©´)": avg_scores["ì²™ì¶”(ì¸¡ë©´)score"]
        }
        # ê°€ì¥ ë‚®ì€ score ë¶€ìœ„ ì°¾ê¸° (None ì œì™¸)
        min_part = min(
            (k for k, v in radar_values.items() if v is not None),
            key=lambda k: radar_values[k]
        )
        output_path = plot_radar_chart(radar_values)
        print(f"  > í‰ê·  ë ˆì´ë” ì°¨íŠ¸ ì €ì¥: {output_path}")
        return {
            "radar_chart_path": output_path,
            "lowest_score_part": min_part,  # ì¶”ê°€!
            "messages": [HumanMessage(content="í‰ê·  ë ˆì´ë” ì°¨íŠ¸ ìƒì„± ì™„ë£Œ")]
        }
    except Exception as e:
        return {"error": f"í‰ê·  ë ˆì´ë” ì°¨íŠ¸ ë…¸ë“œ ì˜¤ë¥˜: {e}"}

def recommend_exercise_node(state: SupervisorGraphState) -> Dict[str, Any]:
    print("[Node 2] ë§ì¶¤ ìš´ë™ ì¶”ì²œ ì¤‘ (from VectorDB)...")
    if state.get("error"): return {}
    try:
        # ë‘ ì¥ì˜ ì§„ë‹¨ í•©ì¹˜ê¸°
        diagnosis_texts = []
        for r in state["pose_analysis_results"]:
            if r is not None and "diagnosis" in r:
                diag = r["diagnosis"].get("korean", "")
                if diag:
                    diagnosis_texts.append(diag)
        diagnosis_text = " ".join(diagnosis_texts)
        # ê°€ì¥ ë‚®ì€ score ë¶€ìœ„ëª…
        lowest_score_part = state.get("lowest_score_part", "")
        prompt = f'''ì•„ë˜ì˜ ìì„¸ ì§„ë‹¨ ë‚´ìš©ê³¼ ì§‘ì¤‘í•´ì•¼ í•  ë¶€ìœ„ë¥¼ ì°¸ê³ í•´ì„œ, ê°€ì¥ ì í•©í•œ 'ë‹¨ í•œ ê°€ì§€'ì˜ ê²€ìƒ‰ì–´ë¥¼ ì¶”ì²œí•´ì¤˜.
        ~ë‚œì´ë„, ~íš¨ê³¼ë¥¼ ê°€ì§„, ~ë¶€ìœ„ì˜, ~ìš´ë™ì˜ ìˆœì„œë¡œ ê²€ìƒ‰ì–´ë¥¼ ì‘ì„±í•´ì•¼í•´.
        VectorDB ê²€ìƒ‰ì— ì‚¬ìš©í•  í‚¤ì›Œë“œ ë¬¸ì¥ ì˜¤ì§ í•œê°œë§Œ ê°„ê²°í•˜ê²Œ í•œ ì¤„ë¡œ ë‹µí•´ì¤˜.

        [ì§„ë‹¨ ë‚´ìš©]
        {diagnosis_text}
        [ì§‘ì¤‘í•´ì•¼ í•  ë¶€ìœ„]
        {lowest_score_part}
        [ì¶œë ¥ ì˜ˆì‹œ]
        - ì¤‘ê¸‰ ë‚œì´ë„ì˜ ìœ ì—°ì„±ì„ ë†’ì´ëŠ” íš¨ê³¼ë¥¼ ê°€ì§„ ê³¨ë°˜ ë¶€ìœ„ì˜ ìŠ¤íŠ¸ë ˆì¹­ ìš´ë™
        [ìƒì„±ëœ ê²€ìƒ‰ì–´]
        '''
        llm_query = llm.invoke(prompt).content.strip()
        print(f"  > LLM ìƒì„± ê²€ìƒ‰ì–´: '{llm_query}'")
        recommended_list = vector_db.search(llm_query, top_k=1)
        if not recommended_list:
            raise ValueError("VectorDBì—ì„œ ì¶”ì²œ ìš´ë™ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        retrieved_exercise = recommended_list[0]
        print(f"  > VectorDB ê²€ìƒ‰ ê²°ê³¼ ìš´ë™ëª…: '{retrieved_exercise['name']}'")
        message = HumanMessage(content=f"DB ê¸°ë°˜ ìš´ë™ ì¶”ì²œ ì™„ë£Œ: {retrieved_exercise['name']}")
        return {"recommended_exercise": retrieved_exercise, "messages": [message]}
    except Exception as e:
        return {"error": f"ìš´ë™ ì¶”ì²œ ë…¸ë“œ ì˜¤ë¥˜: {e}"}

def video_search_node(state: SupervisorGraphState) -> Dict[str, Any]:
    print(f"[Node 3 - ì‹œë„ {state['search_retries'] + 1}] ë³´ì¶© ì˜ìƒ ê²€ìƒ‰ ì¤‘ (Youtube)...")
    if state.get("error"): return {}
    try:
        if state.get("search_retries", 0) > 0:
            print("  > ì˜ìƒ ê²€ì¦ ì‹¤íŒ¨ë¡œ ì¬ê²€ìƒ‰ì„ ì‹¤í–‰í•©ë‹ˆë‹¤. ì´ì „ ì˜ìƒì€ ì œì™¸ë©ë‹ˆë‹¤.")
            tried_urls = state.get("tried_video_urls", [])
        else:
            print("  > ì´ˆê¸° ì˜ìƒ ê²€ìƒ‰ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.")
            tried_urls = []
        # VectorDBì—ì„œ ì¶”ì²œëœ ìš´ë™ëª… ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰ì–´ ìƒì„±
        exercise_name = state["recommended_exercise"]["name"]
        # --- ìŠ¤í¬ì¸  ì „ë¬¸ í›ˆë ¨ í‚¤ì›Œë“œ ì œì™¸ ---
        exclude_keywords = ["ì¶•êµ¬", "ì•¼êµ¬", "ê³¨í”„", "ìˆ˜ì˜", "ë†êµ¬", "í…Œë‹ˆìŠ¤", "íƒêµ¬", "ë°°êµ¬"]
        exclude_str = " ".join([f'-{kw}' for kw in exclude_keywords])
        # ìš´ë™/ìŠ¤íŠ¸ë ˆì¹­ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ, ì•„ë‹ˆë©´ 'ìš´ë™' ë¶™ì„
        if any(x in exercise_name for x in ["ìš´ë™", "ìŠ¤íŠ¸ë ˆì¹­"]):
            search_query = f"{exercise_name} {exclude_str}"
        else:
            search_query = f"{exercise_name} ìš´ë™ {exclude_str}"
        print(f"  > ìœ íŠœë¸Œ ê²€ìƒ‰ì–´: '{search_query}'")
        result = asyncio.run(chatbot_node.run(prompt=search_query, exclude_urls=tried_urls))
        new_url = result.get("youtube_url")
        if not result.get("youtube_url") or "No video found" in result.get("youtube_url"):
            raise ValueError("ì¶”ì²œ ìœ íŠœë¸Œ ì˜ìƒì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        message = HumanMessage(content=f"ìœ íŠœë¸Œ ì˜ìƒ ê²€ìƒ‰ ì™„ë£Œ. URL: {result.get('youtube_url')}")
        updated_tried_urls = tried_urls + [new_url]
        return {
            "chatbot_result": result, 
            "messages": [message], 
            "search_retries": state["search_retries"] + 1,
            "tried_video_urls": updated_tried_urls
        }
    except Exception as e:
        return {"error": f"ì±—ë´‡ ì•¡ì…˜ ë…¸ë“œ ì˜¤ë¥˜: {e}"}

def summarize_video_node(state: SupervisorGraphState) -> Dict[str, Any]:
    print("[Node 4] ìœ íŠœë¸Œ ì˜ìƒ ìš”ì•½ ì¤‘...")
    if state.get("error"): return {}
    try:
        summary_result = youtube_summary_agent.invoke({"url": state["chatbot_result"]["youtube_url"]})
        if summary_result.get("error"):
            raise ValueError(f"ìœ íŠœë¸Œ ìš”ì•½ ì‹¤íŒ¨: {summary_result['error']}")
        
        summary = summary_result.get("script_summary")
        
        comment_count = summary_result.get("comment_count", 0)  # ëŒ“ê¸€ ìˆ˜ ë°˜í™˜(ê¸°ë³¸ê°’ 0)
        
        message = HumanMessage(content=f"ì˜ìƒ ìš”ì•½ ì™„ë£Œ. ëŒ“ê¸€ ìˆ˜: {comment_count}")
        return {
            "youtube_summary": summary, 
            "comment_count": comment_count,
            "messages": [message]
            }
    except Exception as e:
        return {"error": f"ìœ íŠœë¸Œ ìš”ì•½ ë…¸ë“œ ì˜¤ë¥˜: {e}"}
    
class ValidationResult(BaseModel):
    is_relevant: bool = Field(description="ìš”ì•½ ë‚´ìš©ì´ ê±´ê°•ì´ë‚˜ ìš´ë™ê³¼ ê´€ë ¨ì´ ìˆëŠ”ì§€ ì—¬ë¶€")
    reason: str = Field(description="ê´€ë ¨ì´ ìˆê±°ë‚˜ ì—†ëŠ”ì§€ì— ëŒ€í•œ ê°„ëµí•œ ì´ìœ ")

def validate_summary_node(state: SupervisorGraphState) -> Dict[str, Any]:
    print("[Node 5-1] ì˜ìƒ ìš”ì•½ ê²€ì¦ ì¤‘...")
    if state.get("error"): return {}

    summary_dict = state.get("youtube_summary", {})
    summary_text = json.dumps(summary_dict)
    # ë‘ ì¥ì˜ ì§„ë‹¨ í•©ì¹˜ê¸°
    diagnosis_texts = []
    for r in state["pose_analysis_results"]:
        if r is not None and "diagnosis" in r:
            diag = r["diagnosis"].get("korean", "")
            if diag:
                diagnosis_texts.append(diag)
    diagnosis_text = " ".join(diagnosis_texts)
    recommended_exercise = state["recommended_exercise"]["name"]

    # ìš”ì•½ì´ ë„ˆë¬´ ì§§ê±°ë‚˜ ì—†ëŠ” ê²½ìš°, ë°”ë¡œ ë¶€ì í•© íŒì •
    if not summary_dict or len(summary_text) < 50:
        print("  > ê²€ì¦ ì‹¤íŒ¨: ìš”ì•½ ë‚´ìš©ì´ ë„ˆë¬´ ì§§ê±°ë‚˜ ì—†ìŠµë‹ˆë‹¤.")
        message = HumanMessage(content="ìš”ì•½ ê²€ì¦ ì‹¤íŒ¨: ë‚´ìš© ë¶€ì‹¤")
        return {"messages": [message]}

    # LLMì„ í†µí•œ ê´€ë ¨ì„± ê²€ì¦
    structured_validator = llm.with_structured_output(ValidationResult)
    prompt = f"""
ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ìì„¸ êµì •ì„ ìœ„í•œ ìš´ë™ ì˜ìƒì„ í•„í„°ë§í•˜ëŠ” AI ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

[ë¶„ì„í•  ì •ë³´]
- ìì„¸ ì§„ë‹¨: '{diagnosis_text}'
- ì¶”ì²œ ìš´ë™: '{recommended_exercise}'
- ì¶”ì²œ ìš´ë™ì˜ íš¨ê³¼: '{state["recommended_exercise"].get("description", "íš¨ê³¼ ì •ë³´ ì—†ìŒ")}'
- ì˜ìƒ ìš”ì•½: '{summary_text}'

[ìˆ˜í–‰í•  ì‘ì—…]
- 'ìì„¸ ì§„ë‹¨'ì„ ê°œì„ í•˜ê³  'ì¶”ì²œ ìš´ë™'ì„ ìˆ˜í–‰í•˜ëŠ” ë° 'ì˜ìƒ ìš”ì•½'ì˜ ë‚´ìš©ì´ ì í•©í•œì§€ íŒë‹¨í•´ì£¼ì„¸ìš”.
- ê°€ì¥ ë¨¼ì € ì œì™¸ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë‚´ìš©ì´ ìˆëŠ”ì§€ ì‚´í´ë³´ê³ , í•´ë‹¹í•  ì‹œ ë°˜ë“œì‹œ ê´€ë ¨ì—†ìŒìœ¼ë¡œ íŒë‹¨í•´ì•¼ í•©ë‹ˆë‹¤.
- ë˜í•œ ë™ì˜ìƒì˜ ë‚´ìš©ê³¼ 'ì¶”ì²œ ìš´ë™ì˜ íš¨ê³¼'ê°€ ì„œë¡œ ê´€ë ¨ìˆëŠ”ì§€ë„ íŒë‹¨í•´ì•¼ í•©ë‹ˆë‹¤.

[ì œì™¸ ì¡°ê±´]
- **ìŠ¤í¬ì¸  ì „ë¬¸ í›ˆë ¨:** íŠ¹ì • ìŠ¤í¬ì¸ (ì˜ˆ: ì¶•êµ¬, ì•¼êµ¬, ê³¨í”„, ìˆ˜ì˜)ì˜ ê¸°ìˆ  í–¥ìƒì„ ìœ„í•œ í›ˆë ¨ì€ 'ê´€ë ¨ ì—†ìŒ'ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.

[ì¶œë ¥ í˜•ì‹]
ì•„ë˜ JSON í˜•ì‹ì— ë”°ë¼, íŒë‹¨ ê²°ê³¼(`is_relevant`)ì™€ êµ¬ì²´ì ì¸ ì´ìœ (`reason`)ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

{{
  "is_relevant": <true ë˜ëŠ” false>,
  "reason": "<íŒë‹¨ ì´ìœ ë¥¼ ê°„ë‹¨íˆ ì‘ì„±í•©ë‹ˆë‹¤.>"
}}
"""
    
    validation: ValidationResult = structured_validator.invoke(prompt)
    
    if validation.is_relevant:
        print(f"  > ê²€ì¦ ì„±ê³µ: {validation.reason}")
        message = HumanMessage(content="ìš”ì•½ ê²€ì¦ ì„±ê³µ")
    else:
        print(f"  > ê²€ì¦ ì‹¤íŒ¨: {validation.reason}")
        message = HumanMessage(content="ìš”ì•½ ê²€ì¦ ì‹¤íŒ¨: ê´€ë ¨ì„± ë¶€ì¡±")
        
    return {"messages": [message]}

def ask_user_response_node(state: SupervisorGraphState) -> Dict[str, Any]:
    """ì‚¬ìš©ìì—ê²Œ ëŒ“ê¸€ ìš”ì•½ ê´€ì‹¬ ì—¬ë¶€ë¥¼ ë¬»ëŠ” ë…¸ë“œ"""
    print("[Node 5-2] ì‚¬ìš©ì ì‘ë‹µ ìš”ì²­ ì¤‘...")
    
    # ì½˜ì†”ì—ì„œ ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
    print("\n--- ì¶”ê°€ ì •ë³´ ì œê³µ ---")
    print("ì˜ìƒ ìŠ¤í¬ë¦½íŠ¸ ìš”ì•½ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print("ì˜ìƒì— ëŒ€í•œ ëŒ“ê¸€ ë°˜ì‘ë„ ê¶ê¸ˆí•˜ì‹œë‹¤ë©´ ì•Œë ¤ë“œë¦´ê²Œìš”!")
    
    user_input = input("ì‘ë‹µí•´ì£¼ì„¸ìš” (ì˜ˆ: 'ì‘', 'ë„¤', 'ë³´ì—¬ì¤˜' ë˜ëŠ” 'ê´œì°®ì•„', 'ì•„ë‹ˆ'): ").strip()
    
    message = HumanMessage(content=f"ì‚¬ìš©ì ì‘ë‹µ ìˆ˜ì§‘ ì™„ë£Œ: {user_input}")
    return {
        "user_response": user_input,
        "youtube_thread_id": f"thread_{hash(state['chatbot_result']['youtube_url'])}",
        "youtube_config": {"configurable": {"thread_id": f"thread_{hash(state['chatbot_result']['youtube_url'])}"}},
        "messages": [message]
    }
    
def comment_summary_unavailable_node(state: SupervisorGraphState) -> Dict[str, Any]:
    """ëŒ“ê¸€ ìˆ˜ê°€ ì ì–´ ìš”ì•½ ì œê³µì´ ë¶ˆê°€ëŠ¥í•¨ì„ ì•Œë¦¬ëŠ” ë…¸ë“œ"""
    print("[Node 5-3] ëŒ“ê¸€ ìš”ì•½ ì œê³µ ë¶ˆê°€ ì•ˆë‚´")
    
    # ìµœì¢… ê²°ê³¼ì— í‘œì‹œë  ë©”ì‹œì§€ë¥¼ youtube_summaryì— ì¶”ê°€
    updated_youtube_summary = state.get("youtube_summary", {})
    if isinstance(updated_youtube_summary, dict):
         updated_youtube_summary["comment_summary"] = "ëŒ“ê¸€ ê°œìˆ˜ê°€ 10ê°œ ë¯¸ë§Œìœ¼ë¡œ ëŒ“ê¸€ ìš”ì•½ì„ ì œê³µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
    
    message = HumanMessage(content="ëŒ“ê¸€ ìš”ì•½ ì œê³µ ë¶ˆê°€: ëŒ“ê¸€ ìˆ˜ ë¶€ì¡±")
    return {
        "messages": [message],
        "youtube_summary": updated_youtube_summary
    }
    
def rerun_youtube_agent_node(state: SupervisorGraphState) -> Dict[str, Any]:
    """ì‚¬ìš©ì ì‘ë‹µì„ ë°”íƒ•ìœ¼ë¡œ YouTube agentë¥¼ ì¬ì‹¤í–‰í•˜ëŠ” ë…¸ë“œ"""
    print("[Node 5-4] YouTube Agent ì¬ì‹¤í–‰ ì¤‘...")
    
    try:
        # YouTube agentì˜ ë©”ëª¨ë¦¬ ê·¸ë˜í”„ ì‚¬ìš©
        youtube_state = {
            "url": state["chatbot_result"]["youtube_url"],
            "reply": state["user_response"],
            "script_summary": state.get("youtube_summary", {})
        }
        
        # continue_with_memory í•¨ìˆ˜ ì‚¬ìš©í•˜ì—¬ ëŒ“ê¸€ ìš”ì•½ ì‹¤í–‰
        from app.agents.youtube_agent import graph_memory, continue_with_memory
        
        result = continue_with_memory(
            graph_memory, 
            youtube_state, 
            state["youtube_config"], 
            {"reply": state["user_response"], "url": youtube_state["url"]}
        )
        
        # ëŒ“ê¸€ ìš”ì•½ ê²°ê³¼ ì¶”ê°€
        updated_youtube_summary = state.get("youtube_summary", {})
        if result.get("comment_summary"):
            updated_youtube_summary["comment_summary"] = result["comment_summary"]
        
        message = HumanMessage(content="YouTube ëŒ“ê¸€ ìš”ì•½ ì™„ë£Œ")
        return {
            "youtube_summary": updated_youtube_summary,
            "messages": [message]
        }
        
    except Exception as e:
        message = HumanMessage(content=f"YouTube ì¬ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}")
        return {"messages": [message]}

def present_final_result_node(state: SupervisorGraphState) -> Dict[str, Any]:
    print("âœ… ìµœì¢… ê²°ê³¼ ìƒì„± ì¤‘...")
    if state.get("error"):
        final_output = {"success": False, "error_message": state["error"]}
    else:
        # ê°€ì¥ ì ìˆ˜ ë‚®ì€ ë¶€ìœ„ëª…
        lowest_score_part = state.get("lowest_score_part")
        part_to_diag_keyword = {
            "ëª©": "ê±°ë¶ëª©",
            "ì–´ê¹¨": "ì–´ê¹¨",
            "ê³¨ë°˜": "ê³¨ë°˜",
            "ì²™ì¶”(ì •ë©´)": "ì²™ì¶”",
            "ì²™ì¶”(ì¸¡ë©´)": "ì²™ì¶”"
        }
        diag_keyword = part_to_diag_keyword.get(lowest_score_part, "")
        # pose_analysis_resultsì—ì„œ í•´ë‹¹ ë¶€ìœ„ ì§„ë‹¨ë§Œ ì¶”ì¶œ (ë” ìœ ì—°í•˜ê²Œ)
        diagnosis_text = ""
        for r in state["pose_analysis_results"]:
            if r is not None and "diagnosis" in r:
                diag = r["diagnosis"]["korean"]
                for line in diag.splitlines():
                    if diag_keyword in line:
                        diagnosis_text = line.strip()
                        break
                if diagnosis_text:
                    break
                if ":" in diag:
                    after_colon = diag.split(":", 1)[1]
                    if diag_keyword in after_colon:
                        diagnosis_text = diag.strip()
                        break
                for sent in diag.split('.'):
                    if diag_keyword in sent:
                        diagnosis_text = sent.strip()
                        break
            if diagnosis_text:
                break  # í•˜ë‚˜ë§Œ ì¶”ì¶œ
        if not diagnosis_text:
            diagnosis_text = f"{diag_keyword}ì— ëŒ€í•œ êµ¬ì²´ì  ì§„ë‹¨ì´ ì—†ìŠµë‹ˆë‹¤."
        # details ë¦¬ìŠ¤íŠ¸ ë§Œë“¤ê¸° (ê¸°ì¡´ê³¼ ë™ì¼)
        details = []
        for r in state["pose_analysis_results"]:
            if r is not None and "person_analysis" in r:
                pa = r["person_analysis"]
                details.append({
                    "mode": r.get("mode"),
                    "num_keypoints": pa.get("num_keypoints"),
                    "scores": pa.get("scores"),
                    "measurements": pa.get("measurements")
                })
        # --- front/side ì ìˆ˜ í‰ê·  í•©ì¹œ avg_details ìƒì„± ---
        # keys: ê±°ë¶ëª©score, ì–´ê¹¨score, ê³¨ë°˜í‹€ì–´ì§score, ì²™ì¶”íœ¨score, ì²™ì¶”êµ½ìŒscore
        score_keys = ["ê±°ë¶ëª©score", "ì–´ê¹¨score", "ê³¨ë°˜í‹€ì–´ì§score", "ì²™ì¶”íœ¨score", "ì²™ì¶”êµ½ìŒscore"]
        score_sums = {k: [] for k in score_keys}
        for r in state["pose_analysis_results"]:
            if r is not None and "person_analysis" in r:
                scores = r["person_analysis"].get("scores", {})
                for k in score_keys:
                    v = scores.get(k)
                    if v is not None:
                        score_sums[k].append(v)
        avg_scores = {k: (sum(vs)/len(vs) if vs else None) for k, vs in score_sums.items()}
        avg_details = {"avg_scores": avg_scores}
        # --- avg_diagnosis: ê°€ì¥ ë‚®ì€ í‰ê·  score ë¶€ìœ„ì— ëŒ€í•œ ì§„ë‹¨ ---
        # radar_valuesì™€ ë™ì¼í•˜ê²Œ ë§¤í•‘
        radar_part_map = {
            "ëª©": "ê±°ë¶ëª©score",
            "ì–´ê¹¨": "ì–´ê¹¨score",
            "ê³¨ë°˜": "ê³¨ë°˜í‹€ì–´ì§score",
            "ì²™ì¶”(ì •ë©´)": "ì²™ì¶”íœ¨score",
            "ì²™ì¶”(ì¸¡ë©´)": "ì²™ì¶”êµ½ìŒscore"
        }
        # í‰ê·  score ì¤‘ ê°€ì¥ ë‚®ì€ ë¶€ìœ„
        min_avg_part = None
        min_avg_score = float('inf')
        for part, key in radar_part_map.items():
            val = avg_scores.get(key)
            if val is not None and val < min_avg_score:
                min_avg_score = val
                min_avg_part = part
        avg_diag_keyword = part_to_diag_keyword.get(min_avg_part, "")
        avg_diagnosis_text = ""
        for r in state["pose_analysis_results"]:
            if r is not None and "diagnosis" in r:
                diag = r["diagnosis"]["korean"]
                for line in diag.splitlines():
                    if avg_diag_keyword in line:
                        avg_diagnosis_text = line.strip()
                        break
                if avg_diagnosis_text:
                    break
                if ":" in diag:
                    after_colon = diag.split(":", 1)[1]
                    if avg_diag_keyword in after_colon:
                        avg_diagnosis_text = diag.strip()
                        break
                for sent in diag.split('.'):
                    if avg_diag_keyword in sent:
                        avg_diagnosis_text = sent.strip()
                        break
            if avg_diagnosis_text:
                break
        if not avg_diagnosis_text:
            avg_diagnosis_text = f"{avg_diag_keyword}ì— ëŒ€í•œ êµ¬ì²´ì  ì§„ë‹¨ì´ ì—†ìŠµë‹ˆë‹¤."
        # --- avg_feedback: front/side í†µí•© feedback ---
        feedbacks = []
        for r in state["pose_analysis_results"]:
            if r is not None and "person_analysis" in r:
                fb = r["person_analysis"].get("feedback", {})
                overall = fb.get("overall")
                if overall and overall not in feedbacks:
                    feedbacks.append(overall)
        avg_feedback = "\n".join(feedbacks) if feedbacks else "í†µí•© í”¼ë“œë°±ì´ ì—†ìŠµë‹ˆë‹¤."
        # --- ìµœì¢… ê²°ê³¼ ìƒì„± ---
        final_output = {
            "success": True,
            "analysis": {
                # diagnosis í•„ë“œ ì™„ì „ ì‚­ì œ
                "details": details,
                "avg_details": avg_details,
                "avg_diagnosis": avg_diagnosis_text,
                "avg_feedback": avg_feedback
            },
            "primary_recommendation": state.get("recommended_exercise"), 
            "supplementary_video": { 
                "search_phrase": state.get("chatbot_result", {}).get("search_phrase"),
                "youtube_url": state.get("chatbot_result", {}).get("youtube_url"),
                "video_summary": state.get("youtube_summary") or {}
            },            
        }
    print("\n--- ìµœì¢… ê²°ê³¼ (JSON) ---")
    print(json.dumps(final_output, indent=2, ensure_ascii=False))
    return {"final_output": final_output}

# --- 4. Supervisor ë…¸ë“œ (ì¬ê²€ìƒ‰ ë¡œì§ ì¶”ê°€) ---
def supervisor_node(state: SupervisorGraphState) -> Dict[str, str]:
    print("[Supervisor] ë‹¤ìŒ ì‘ì—… ê²°ì • ì¤‘...")
    last_message = state['messages'][-1].content
    
    if "ë‘ ì‚¬ì§„ ë¶„ì„ ì™„ë£Œ" in last_message:
        return {"next_agent": "plot_avg_radar_chart"}
    elif "í‰ê·  ë ˆì´ë” ì°¨íŠ¸ ìƒì„± ì™„ë£Œ" in last_message:
        return {"next_agent": "recommend_exercise"}
    elif "DB ê¸°ë°˜ ìš´ë™ ì¶”ì²œ ì™„ë£Œ" in last_message:
        return {"next_agent": "video_search"}
    elif "ìœ íŠœë¸Œ ì˜ìƒ ê²€ìƒ‰ ì™„ë£Œ" in last_message:
        return {"next_agent": "summarize_video"}
    elif "ì˜ìƒ ìš”ì•½ ì™„ë£Œ" in last_message:
        return {"next_agent": "validate_summary"}
    elif "ìš”ì•½ ê²€ì¦ ì„±ê³µ" in last_message:
        # ê²€ì¦ ì„±ê³µ í›„ ëŒ“ê¸€ ìˆ˜ì— ë”°ë¼ ë¶„ê¸°
        comment_count = state.get("comment_count", 0)
        if comment_count >= 10:
            print(f"  > ëŒ“ê¸€ ìˆ˜({comment_count})ê°€ 10ê°œ ì´ìƒì´ë¯€ë¡œ ì‚¬ìš©ìì—ê²Œ ì§ˆë¬¸í•©ë‹ˆë‹¤.")
            return {"next_agent": "ask_user_response"}
        else:
            print(f"  > ëŒ“ê¸€ ìˆ˜({comment_count})ê°€ 10ê°œ ë¯¸ë§Œì´ë¯€ë¡œ ìš”ì•½ì„ ì œê³µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return {"next_agent": "comment_summary_unavailable"}
    elif "ì‚¬ìš©ì ì‘ë‹µ ìˆ˜ì§‘ ì™„ë£Œ" in last_message:
        # ì‚¬ìš©ì ì‘ë‹µì— ë”°ë¼ ë¶„ê¸°
        user_response = state.get("user_response", "").lower()
        
        # ê¸ì •ì  ì‘ë‹µì¸ì§€ í™•ì¸
        positive_responses = ["ì‘", "ë„¤", "ë³´ì—¬ì¤˜", "ê¶ê¸ˆí•´", "ê·¸ë˜", "ì¢‹ì•„", "yes", "y"]
        if any(pos in user_response for pos in positive_responses):
            return {"next_agent": "rerun_youtube_agent"}
        else:
            # ë¶€ì •ì  ì‘ë‹µì´ë©´ ë°”ë¡œ ìµœì¢… ê²°ê³¼ë¡œ
            return {"next_agent": "present_final_result"}
    elif "YouTube ëŒ“ê¸€ ìš”ì•½ ì™„ë£Œ" in last_message:
        return {"next_agent": "present_final_result"}
    elif "ëŒ“ê¸€ ìš”ì•½ ì œê³µ ë¶ˆê°€" in last_message: 
        return {"next_agent": "present_final_result"}
    elif "YouTube ì¬ì‹¤í–‰ ì‹¤íŒ¨" in last_message:
        return {"next_agent": "present_final_result"}
    elif "ìš”ì•½ ê²€ì¦ ì‹¤íŒ¨" in last_message:
        if state["search_retries"] >= 2:
            return {"next_agent": "present_final_result"}
        else:
            return {"next_agent": "video_search"}
    else:
        return {"next_agent": "END"}
    
    
# --- 5. ê·¸ë˜í”„ êµ¬ì„± (Supervisor íŒ¨í„´) ---
workflow = StateGraph(SupervisorGraphState)

workflow.add_node("analyze_both_poses", analyze_both_poses_node)
workflow.add_node("plot_avg_radar_chart", plot_avg_radar_chart_node)
workflow.add_node("recommend_exercise", recommend_exercise_node)
workflow.add_node("video_search", video_search_node)
workflow.add_node("summarize_video", summarize_video_node)
workflow.add_node("validate_summary", validate_summary_node)
workflow.add_node("present_final_result", present_final_result_node)
workflow.add_node("ask_user_response", ask_user_response_node)
workflow.add_node("rerun_youtube_agent", rerun_youtube_agent_node)
workflow.add_node("comment_summary_unavailable", comment_summary_unavailable_node)
workflow.add_node("supervisor", supervisor_node)

workflow.set_entry_point("analyze_both_poses")
workflow.add_edge("analyze_both_poses", "supervisor")
workflow.add_edge("plot_avg_radar_chart", "supervisor")
workflow.add_edge("recommend_exercise", "supervisor")
workflow.add_edge("video_search", "supervisor")
workflow.add_edge("summarize_video", "supervisor")
workflow.add_edge("validate_summary", "supervisor")
workflow.add_edge("ask_user_response", "supervisor")
workflow.add_edge("rerun_youtube_agent", "supervisor")
workflow.add_edge("comment_summary_unavailable", "supervisor")

workflow.add_conditional_edges(
    "supervisor",
    lambda state: state["next_agent"],
    {
        "plot_avg_radar_chart": "plot_avg_radar_chart",
        "recommend_exercise": "recommend_exercise",
        "video_search": "video_search",
        "summarize_video": "summarize_video",
        "validate_summary": "validate_summary",
        "ask_user_response": "ask_user_response",  
        "rerun_youtube_agent": "rerun_youtube_agent", 
        "comment_summary_unavailable": "comment_summary_unavailable",
        "present_final_result": "present_final_result",
        "END": END
    }
)
workflow.add_edge("present_final_result", END)
app = workflow.compile()

# --- 6. ì‹¤í–‰ ì˜ˆì‹œ ---
if __name__ == "__main__":
    initial_state = {
        "messages": [HumanMessage(content="ìì„¸ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.")],
        "image_paths": ["app/services/images/test_front2.jpg", "app/services/images/test_side2.jpg"],
        "analysis_modes": ["front", "side"],
        "search_retries": 0,
        "comment_count": 0,
        "user_response": None,
        "youtube_thread_id": None,
        "youtube_config": None
    }
    
    print("ğŸš€ AI í”¼íŠ¸ë‹ˆìŠ¤ ì½”ì¹˜ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤ (Interactive Mode).")
    print(f"   - ì…ë ¥ ì´ë¯¸ì§€: {initial_state['image_paths']}")
    print(f"   - ë¶„ì„ ëª¨ë“œ: {initial_state['analysis_modes']}")
    print("-" * 50)

    app.invoke(initial_state)

    print("\n" + "-"*50)
    print("ğŸ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì™„ë£Œ.")