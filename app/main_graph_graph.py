import os
import json
import asyncio
from typing import TypedDict, Dict, Any, Optional, Annotated
from dotenv import load_dotenv
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langchain_core.messages import HumanMessage
from pydantic import BaseModel, Field
from langchain_openai import ChatOpenAI
from fastapi import FastAPI, HTTPException, Request
from fastapi.responses import JSONResponse
import cloudinary.uploader
import requests
import traceback
import re # Added for comment summary endpoint

# --- ì„œë¹„ìŠ¤ ë° ë…¸ë“œ í´ë˜ìŠ¤ Import ---
from app.services.posture_analyzer import PostureAnalyzer
from app.agents.youtube_agent import graph as youtube_summary_agent
from app.nodes.chatbot_node import ChatbotActionNode
from app.services.exercise_vector_db import ExerciseVectorDB
from data_server import plot_radar_chart

load_dotenv()

cloudinary.config(
    cloud_name = os.getenv("CLOUDINARY_CLOUD_NAME"),
    api_key = os.getenv("CLOUDINARY_API_KEY"),
    api_secret = os.getenv("CLOUDINARY_API_SECRET")
)

# --- 1. ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ---
llm = ChatOpenAI(model="gpt-4o-mini")
posture_analyzer = PostureAnalyzer(model_path="models/yolopose_v1.pt")
chatbot_node = ChatbotActionNode()
vector_db = ExerciseVectorDB()

# --- 2. ê·¸ë˜í”„ ìƒíƒœ (Supervisor íŒ¨í„´ìš©) ---
class SupervisorGraphState(TypedDict):
    # ê° ë…¸ë“œì˜ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë©”ì‹œì§€ í˜•íƒœë¡œ ëˆ„ì í•˜ì—¬ ëŒ€í™”ì˜ íë¦„ì„ ê´€ë¦¬
    messages: Annotated[list, add_messages]
    
    # ë‹¤ìŒìœ¼ë¡œ í˜¸ì¶œí•  ë…¸ë“œì˜ ì´ë¦„ì„ ì €ì¥
    next_agent: str
    
    # ì›ë³¸ ìš”ì²­ ë°ì´í„°
    image_path: str
    analysis_mode: str
    
    # ì¬ê²€ìƒ‰ íšŸìˆ˜ ì¶”ì 
    search_retries: int
    
    # ë…¸ë“œë³„ ê²°ê³¼ ë°ì´í„°
    pose_analysis_result: Dict[str, Any]
    diagnosis: Dict[str, str]
    recommended_exercise: Dict[str, Any]
    chatbot_result: Dict[str, Any]
    youtube_summary: Optional[Dict[str, Any]]
    comment_count: int
    final_output: Dict[str, Any]
    error: Optional[str]
    
    # ì‚¬ìš©ì ì‘ë‹µ ê´€ë ¨ í•„ë“œ(ëŒ“ê¸€ ìš”ì•½ì—¬ë¶€ ê²°ì •)
    user_response: Optional[str]  # ì‚¬ìš©ìì˜ ì‘ë‹µ
    youtube_thread_id: Optional[str]  # YouTube agentì˜ ìŠ¤ë ˆë“œ ID
    youtube_config: Optional[Dict[str, Any]]  # YouTube agent ì„¤ì •
    
    # ì¬ê²€ìƒ‰ ì‹œ ì œì™¸í•  URL ë¦¬ìŠ¤íŠ¸
    tried_video_urls: list[str]
    
    # ë ˆì´ë” ì°¨íŠ¸ ê²½ë¡œ (plot_radar_chart_nodeì—ì„œ ë°˜í™˜)
    radar_chart_path: str

# --- 3. LangGraph ë…¸ë“œ í•¨ìˆ˜ ì¬ì •ì˜ ---

# ê° ë…¸ë“œëŠ” ì´ì œ 'messages'ì— ìì‹ ì˜ ì‹¤í–‰ ê²°ê³¼ë¥¼ HumanMessage í˜•íƒœë¡œ ì¶”ê°€í•˜ì—¬ ìŠˆí¼ë°”ì´ì €ì—ê²Œ ë³´ê³ í•©ë‹ˆë‹¤.
def analyze_user_pose_node(state: SupervisorGraphState) -> Dict[str, Any]:
    print("[Node 1] ìì„¸ ë¶„ì„ ì¤‘...")
    try:
        
        analysis_result = posture_analyzer.analyze_posture(state["image_path"], mode=state["analysis_mode"])
        if not analysis_result.get("success") or not analysis_result.get("pose_data"):
            raise ValueError("ìì„¸ ë¶„ì„ ì‹¤íŒ¨")
            
        person_analysis = analysis_result["pose_data"][0]
        diagnosis_texts = posture_analyzer.generate_ollama_diagnosis(person_analysis, state["analysis_mode"])
        
        message = HumanMessage(content=f"ìì„¸ ë¶„ì„ ì™„ë£Œ. ì§„ë‹¨: {diagnosis_texts['korean']}")
        return {"pose_analysis_result": person_analysis, "diagnosis": diagnosis_texts, "messages": [message]}
    except Exception as e:
        return {"error": f"ìì„¸ ë¶„ì„ ë…¸ë“œ ì˜¤ë¥˜: {e}"}

def plot_radar_chart_node(state: SupervisorGraphState) -> Dict[str, Any]:
    print("[Node X] ìì„¸ ë¶„ì„ ê²°ê³¼ ë ˆì´ë” ì°¨íŠ¸ ìƒì„± ì¤‘...")
    try:
        scores = state["pose_analysis_result"]["scores"]
        radar_values = {
            "ëª©": scores["ê±°ë¶ëª©score"],
            "ì–´ê¹¨": scores["ì–´ê¹¨score"],
            "ê³¨ë°˜": scores["ê³¨ë°˜í‹€ì–´ì§score"],
            "ì²™ì¶”(ì •ë©´)": scores["ì²™ì¶”íœ¨score"],
            "ì²™ì¶”(ì¸¡ë©´)": scores["ì²™ì¶”êµ½ìŒscore"]
        }
        output_path = plot_radar_chart(radar_values)
        print(f"  > ë ˆì´ë” ì°¨íŠ¸ ì €ì¥: {output_path}")
        # ê¸°ì¡´ stateì— radar_chart_pathë¥¼ ì¶”ê°€í•´ì„œ ë°˜í™˜
        return {
            **state,
            "radar_chart_path": output_path,
            "messages": [HumanMessage(content="ë ˆì´ë” ì°¨íŠ¸ ìƒì„± ì™„ë£Œ")]
        }
    except Exception as e:
        print("plot_radar_chart_node ì—ëŸ¬:", e)
        return {**state, "error": f"ë ˆì´ë” ì°¨íŠ¸ ë…¸ë“œ ì˜¤ë¥˜: {e}"}

def recommend_exercise_node(state: SupervisorGraphState) -> Dict[str, Any]:
    print("[Node 2] ë§ì¶¤ ìš´ë™ ì¶”ì²œ ì¤‘ (from VectorDB)...")
    if state.get("error"): return {}
    try:
        # ì§„ë‹¨ ë‚´ìš© ì•ˆì „í•˜ê²Œ ì¶”ì¶œ
        diagnosis_obj = state.get("diagnosis", {})
        diagnosis_text = diagnosis_obj.get("korean", "ì§„ë‹¨ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ê°€ ìˆìœ¼ë©´ í•¨ê»˜ ê³ ë ¤
        user_message = state.get("user_message", "")
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ì—ì„œ "ìì„¸ ë¶„ì„ ê²°ê³¼:" ë¶€ë¶„ ì œê±°í•˜ê³  ì‹¤ì œ ìš”ì²­ë§Œ ì¶”ì¶œ
        if user_message and "ìì„¸ ë¶„ì„ ê²°ê³¼:" in user_message:
            # "ìì„¸ ë¶„ì„ ê²°ê³¼: ... ì´ì— ë§ëŠ” ìš´ë™ì„ ì¶”ì²œí•´ì£¼ì„¸ìš”." í˜•íƒœì—ì„œ ì‹¤ì œ ìš”ì²­ë§Œ ì¶”ì¶œ
            parts = user_message.split("ì´ì— ë§ëŠ”")
            if len(parts) > 1:
                # ì§„ë‹¨ ë¶€ë¶„ì€ ì œê±°í•˜ê³  ìš”ì²­ ë¶€ë¶„ë§Œ ì‚¬ìš©
                user_request = parts[1].replace("ìš´ë™ì„ ì¶”ì²œí•´ì£¼ì„¸ìš”.", "").replace("ìš´ë™ ì˜ìƒì„ ì¶”ì²œí•´ì£¼ì„¸ìš”.", "").strip()
                if user_request:
                    user_message = user_request
            else:
                user_message = ""
        
        context = f"ì§„ë‹¨: {diagnosis_text}"
        if user_message:
            context += f"\nì‚¬ìš©ì ìš”ì²­: {user_message}"
        
        print(f"  > ì§„ë‹¨ ë‚´ìš©: {diagnosis_text}")
        print(f"  > ì‚¬ìš©ì ìš”ì²­: {user_message}")
        
        # LLMì„ ì‚¬ìš©í•´ ì§„ë‹¨ ë‚´ìš©ê³¼ ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ê³ ë ¤í•˜ì—¬ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
        prompt = f"""ì•„ë˜ì˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°€ì¥ ì í•©í•œ ìš´ë™ ê²€ìƒ‰ì–´ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

[ë¶„ì„ ì •ë³´]
{context}

[ê²€ìƒ‰ì–´ ìƒì„± ê·œì¹™]
1. ~ë‚œì´ë„, ~íš¨ê³¼ë¥¼ ê°€ì§„, ~ë¶€ìœ„ì˜, ~ìš´ë™ì˜ ìˆœì„œë¡œ ì‘ì„±
2. ì‚¬ìš©ì ìš”ì²­ì´ ìˆìœ¼ë©´ ê·¸ ë‚´ìš©ì„ ìš°ì„  ê³ ë ¤
3. ì§„ë‹¨ ë‚´ìš©ê³¼ ì‚¬ìš©ì ìš”ì²­ì„ ëª¨ë‘ ë§Œì¡±í•˜ëŠ” ìš´ë™ì„ ì°¾ì„ ìˆ˜ ìˆë„ë¡ ì‘ì„±
4. VectorDB ê²€ìƒ‰ì— ì‚¬ìš©í•  í‚¤ì›Œë“œ ë¬¸ì¥ ì˜¤ì§ í•œê°œë§Œ ê°„ê²°í•˜ê²Œ í•œ ì¤„ë¡œ ë‹µí•´ì¤˜

[ì¶œë ¥ ì˜ˆì‹œ]
- ì¤‘ê¸‰ ë‚œì´ë„ì˜ ìœ ì—°ì„±ì„ ë†’ì´ëŠ” íš¨ê³¼ë¥¼ ê°€ì§„ ê³¨ë°˜ ë¶€ìœ„ì˜ ìŠ¤íŠ¸ë ˆì¹­ ìš´ë™
- ì´ˆê¸‰ ë‚œì´ë„ì˜ ëª© í†µì¦ ì™„í™” íš¨ê³¼ë¥¼ ê°€ì§„ ëª© ë¶€ìœ„ì˜ ìŠ¤íŠ¸ë ˆì¹­ ìš´ë™

[ìƒì„±ëœ ê²€ìƒ‰ì–´]
"""
        llm_query = llm.invoke(prompt).content.strip()
        print(f"  > LLM ìƒì„± ê²€ìƒ‰ì–´: '{llm_query}'")
        
        recommended_list = vector_db.search(llm_query, top_k=1)
        
        if not recommended_list:
            # ì²« ë²ˆì§¸ ê²€ìƒ‰ì´ ì‹¤íŒ¨í•˜ë©´ ë” ì¼ë°˜ì ì¸ ê²€ìƒ‰ì–´ë¡œ ì¬ì‹œë„
            print("  > ì²« ë²ˆì§¸ ê²€ìƒ‰ ì‹¤íŒ¨, ì¼ë°˜ì ì¸ ê²€ìƒ‰ì–´ë¡œ ì¬ì‹œë„...")
            fallback_prompt = f"""ì•„ë˜ ì§„ë‹¨ ë‚´ìš©ì— ë§ëŠ” ì¼ë°˜ì ì¸ ìš´ë™ ê²€ìƒ‰ì–´ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

[ì§„ë‹¨ ë‚´ìš©]
{diagnosis_text}

[ê²€ìƒ‰ì–´ ìƒì„± ê·œì¹™]
- ì§„ë‹¨ ë‚´ìš©ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ë¶€ìœ„ë‚˜ ì¦ìƒì„ ì¤‘ì‹¬ìœ¼ë¡œ ê²€ìƒ‰ì–´ ìƒì„±
- "ìŠ¤íŠ¸ë ˆì¹­", "ìš´ë™", "êµì •" ë“±ì˜ í‚¤ì›Œë“œ í¬í•¨
- ê°„ê²°í•˜ê²Œ í•œ ì¤„ë¡œ ì‘ì„±

[ìƒì„±ëœ ê²€ìƒ‰ì–´]
"""
            fallback_query = llm.invoke(fallback_prompt).content.strip()
            print(f"  > Fallback ê²€ìƒ‰ì–´: '{fallback_query}'")
            recommended_list = vector_db.search(fallback_query, top_k=1)
            
            if not recommended_list:
                raise ValueError("VectorDBì—ì„œ ì¶”ì²œ ìš´ë™ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        
        # VectorDBì—ì„œ ì°¾ì€ ì‹¤ì œ ìš´ë™ ê°ì²´ë¥¼ ë³€ìˆ˜ì— ì €ì¥
        retrieved_exercise = recommended_list[0]
        print(f"  > VectorDB ê²€ìƒ‰ ê²°ê³¼ ìš´ë™ëª…: '{retrieved_exercise['name']}'")
        print(f"  > ìš´ë™ ì„¤ëª…: '{retrieved_exercise.get('description', 'ì„¤ëª… ì—†ìŒ')}'")
        
        message = HumanMessage(content=f"DB ê¸°ë°˜ ìš´ë™ ì¶”ì²œ ì™„ë£Œ: {retrieved_exercise['name']}")
        
        # ìƒíƒœ(state)ì— DBì—ì„œ ì§ì ‘ ì°¾ì€ ìš´ë™ ê°ì²´ì™€ ê²€ìƒ‰ì–´ë¥¼ ì €ì¥
        return {
            "recommended_exercise": retrieved_exercise, 
            "search_query": llm_query,  # ìƒì„±ëœ ê²€ìƒ‰ì–´ë„ ì €ì¥
            "messages": [message]
        }
        
    except Exception as e:
        return {"error": f"ìš´ë™ ì¶”ì²œ ë…¸ë“œ ì˜¤ë¥˜: {e}"}

def ai_coach_interaction_node(state: SupervisorGraphState) -> Dict[str, Any]:
    """AI ì½”ì¹˜ì™€ì˜ ëŒ€í™” ë…¸ë“œ"""
    print("[Node - AI ì½”ì¹˜] ì‚¬ìš©ìì™€ ëŒ€í™” ì¤‘...")
    try:
        # ì§„ë‹¨ ë‚´ìš© ì•ˆì „í•˜ê²Œ ì¶”ì¶œ
        diagnosis_obj = state.get("diagnosis", {})
        diagnosis_text = diagnosis_obj.get("korean", "ì§„ë‹¨ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        recommended_exercise = state["recommended_exercise"]["name"]
        user_message = state.get("user_message", "")
        search_query = state.get("search_query", "")  # recommend_exercise_nodeì—ì„œ ìƒì„±ëœ ê²€ìƒ‰ì–´
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ì—ì„œ "ìì„¸ ë¶„ì„ ê²°ê³¼:" ë¶€ë¶„ ì œê±°í•˜ê³  ì‹¤ì œ ìš”ì²­ë§Œ ì¶”ì¶œ
        if user_message and "ìì„¸ ë¶„ì„ ê²°ê³¼:" in user_message:
            parts = user_message.split("ì´ì— ë§ëŠ”")
            if len(parts) > 1:
                user_request = parts[1].replace("ìš´ë™ì„ ì¶”ì²œí•´ì£¼ì„¸ìš”.", "").replace("ìš´ë™ ì˜ìƒì„ ì¶”ì²œí•´ì£¼ì„¸ìš”.", "").strip()
                if user_request:
                    user_message = user_request
            else:
                user_message = ""
        
        print(f"  > ì§„ë‹¨ ë‚´ìš©: {diagnosis_text}")
        print(f"  > ì¶”ì²œ ìš´ë™: {recommended_exercise}")
        print(f"  > ìƒì„±ëœ ê²€ìƒ‰ì–´: {search_query}")
        print(f"  > ì‚¬ìš©ì ìš”ì²­: {user_message}")
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ê°€ ìˆìœ¼ë©´ ë” êµ¬ì²´ì ì¸ ì‘ë‹µ ìƒì„±
        if user_message:
            prompt = f"""
            ë‹¹ì‹ ì€ AI í”¼íŠ¸ë‹ˆìŠ¤ ì½”ì¹˜ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ êµ¬ì²´ì ì¸ ìš”ì²­ì— ëŒ€í•´ ë‹µë³€í•´ì£¼ì„¸ìš”.
            
            [ì‚¬ìš©ì ìš”ì²­]
            {user_message}
            
            [ì§„ë‹¨ ë‚´ìš©]
            {diagnosis_text}
            
            [ì¶”ì²œ ìš´ë™]
            {recommended_exercise}
            
            [ìš´ë™ ê²€ìƒ‰ ê¸°ì¤€]
            {search_query}
            
            [ìš´ë™ ì„¤ëª…]
            {state["recommended_exercise"].get("description", "ì„¤ëª… ì—†ìŒ")}
            
            [ë‹µë³€ ìš”êµ¬ì‚¬í•­]
            1. ì‚¬ìš©ìì˜ êµ¬ì²´ì ì¸ ìš”ì²­ì— ì§ì ‘ì ìœ¼ë¡œ ë‹µë³€
            2. ì§„ë‹¨ ë‚´ìš©ê³¼ ì¶”ì²œ ìš´ë™ì„ ì—°ê²°í•˜ì—¬ ì„¤ëª…
            3. ìš´ë™ ê²€ìƒ‰ ê¸°ì¤€ì— ë§ëŠ” ìš´ë™ì˜ íŠ¹ì§•ì„ ê°•ì¡°
            4. ìš´ë™ì˜ íš¨ê³¼ì™€ ì‹¤ì‹œ ë°©ë²•ì„ êµ¬ì²´ì ìœ¼ë¡œ ì•ˆë‚´
            5. ë™ê¸°ë¶€ì—¬ì™€ í•¨ê»˜ ì‹¤ì²œ ê°€ëŠ¥í•œ ì¡°ì–¸ ì œê³µ
            6. ì¹œê·¼í•˜ê³  ê²©ë ¤í•˜ëŠ” í†¤ìœ¼ë¡œ ë‹µë³€
            """
        else:
            # ì¼ë°˜ì ì¸ AI ì½”ì¹˜ ì‘ë‹µ
            prompt = f"""
            ë‹¹ì‹ ì€ AI í”¼íŠ¸ë‹ˆìŠ¤ ì½”ì¹˜ì…ë‹ˆë‹¤. ì•„ë˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì™€ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ì„¸ìš”.
            
            [ì§„ë‹¨ ë‚´ìš©]
            {diagnosis_text}
            
            [ì¶”ì²œ ìš´ë™]
            {recommended_exercise}
            
            [ìš´ë™ ê²€ìƒ‰ ê¸°ì¤€]
            {search_query}
            
            [ìš´ë™ ì„¤ëª…]
            {state["recommended_exercise"].get("description", "ì„¤ëª… ì—†ìŒ")}
            
            ì‚¬ìš©ìì—ê²Œ ìš´ë™ì˜ ì¤‘ìš”ì„±ê³¼ ìì„¸ êµì •ì˜ í•„ìš”ì„±ì„ ì„¤ëª…í•˜ê³ , ë™ê¸°ë¶€ì—¬ë¥¼ ì œê³µí•˜ì„¸ìš”.
            ìš´ë™ ê²€ìƒ‰ ê¸°ì¤€ì— ë§ëŠ” ìš´ë™ì˜ íŠ¹ì§•ë„ í•¨ê»˜ ì–¸ê¸‰í•´ì£¼ì„¸ìš”.
            """
        
        response = llm.invoke(prompt).content.strip()
        print(f"  > AI ì½”ì¹˜ ì‘ë‹µ: {response}")
        
        message = HumanMessage(content=f"AI ì½”ì¹˜ ëŒ€í™” ì™„ë£Œ: {response}")
        return {"messages": [message]}
    except Exception as e:
        return {"error": f"AI ì½”ì¹˜ ë…¸ë“œ ì˜¤ë¥˜: {e}"}

async def video_search_node(state: SupervisorGraphState) -> Dict[str, Any]:
    print(f"[Node 3 - ì‹œë„ {state['search_retries'] + 1}] ë³´ì¶© ì˜ìƒ ê²€ìƒ‰ ì¤‘ (Youtube)...")
    if state.get("error"): return {}
    try:
        # search_retries ê°’ì— ë”°ë¼ ë¶„ê¸° ë¡œì§ ì¶”ê°€
        if state.get("search_retries", 0) > 0:
            # ì¬ê²€ìƒ‰ì¼ ê²½ìš° (search_retries > 0)
            print("   > ì˜ìƒ ê²€ì¦ ì‹¤íŒ¨ë¡œ ì¬ê²€ìƒ‰ì„ ì‹¤í–‰í•©ë‹ˆë‹¤. ì´ì „ ì˜ìƒì€ ì œì™¸ë©ë‹ˆë‹¤.")
            tried_urls = state.get("tried_video_urls", [])
        else:
            # ì´ˆê¸° ê²€ìƒ‰ì¼ ê²½ìš° (search_retries == 0)
            print("   > ì´ˆê¸° ì˜ìƒ ê²€ìƒ‰ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.")
            tried_urls = []
            
        # recommend_exercise_nodeì—ì„œ ìƒì„±ëœ ê²€ìƒ‰ì–´ë¥¼ ë‹¨ìˆœí™”í•˜ì—¬ ì‚¬ìš©
        original_search_query = state.get("search_query", "")
        
        if original_search_query:
            print(f"  > ì›ë³¸ ê²€ìƒ‰ì–´: '{original_search_query}'")
            # ê²€ìƒ‰ì–´ë¥¼ ë‹¨ìˆœí™” (ìš´ë™ëª…ë§Œ ì¶”ì¶œ)
            exercise_name = state["recommended_exercise"]["name"]
            if "ìì„¸" in exercise_name or "ìŠ¤íŠ¸ë ˆì¹­" in exercise_name:
                search_query = f"{exercise_name}"
            else:
                search_query = f"{exercise_name} ìš´ë™"
            print(f"  > ë‹¨ìˆœí™”ëœ ê²€ìƒ‰ì–´ ì‚¬ìš©: '{search_query}'")
        else:
            # ê²€ìƒ‰ì–´ê°€ ì—†ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ìƒì„±
            exercise_name = state["recommended_exercise"]["name"]
            if "ìì„¸" in exercise_name or "ìŠ¤íŠ¸ë ˆì¹­" in exercise_name:
                search_query = f"{exercise_name}"
            else:
                search_query = f"{exercise_name} ìš´ë™"
            print(f"  > ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ê²€ìƒ‰ì–´ ìƒì„±: '{search_query}'")
            
        result = await chatbot_node.run(prompt=search_query, exclude_urls=tried_urls)
        
        print(f"chatbot_node result: {result}")
        
        new_url = result.get("youtube_url")
        
        if not result.get("youtube_url") or "No video found" in result.get("youtube_url"):
            print("  > YouTube ê²€ìƒ‰ ì‹¤íŒ¨. ê¸°ë³¸ ì‘ë‹µìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
            # YouTube ê²€ìƒ‰ì´ ì‹¤íŒ¨í•´ë„ ê¸°ë³¸ ì‘ë‹µ ë°˜í™˜
            result = {
                "youtube_url": None,
                "video_title": "ì¶”ì²œ ìš´ë™ ì˜ìƒ",
                "search_phrase": search_query
            }

        # video_titleì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì„¤ì •
        if not result.get("video_title"):
            result["video_title"] = "ì¶”ì²œ ìš´ë™ ì˜ìƒ"
            print(f"Set default video title: {result['video_title']}")

        print(f"Final chatbot_result: {result}")
        message = HumanMessage(content=f"ìœ íŠœë¸Œ ì˜ìƒ ê²€ìƒ‰ ì™„ë£Œ. URL: {result.get('youtube_url')}")
        updated_tried_urls = tried_urls + [new_url] if new_url else tried_urls
        return {
            "chatbot_result": result, 
            "messages": [message], 
            "search_retries": state["search_retries"] + 1,
            "tried_video_urls": updated_tried_urls # ìƒíƒœ ì—…ë°ì´íŠ¸
        }
    except Exception as e:
        return {"error": f"ì±—ë´‡ ì•¡ì…˜ ë…¸ë“œ ì˜¤ë¥˜: {e}"}

async def summarize_video_node(state: SupervisorGraphState) -> Dict[str, Any]:
    print("[Node 4] ìœ íŠœë¸Œ ì˜ìƒ ìš”ì•½ ì¤‘...")
    if state.get("error"): return {}
    try:
        summary_result = youtube_summary_agent.invoke({"url": state["chatbot_result"]["youtube_url"]})
        if summary_result.get("error"):
            raise ValueError(f"ìœ íŠœë¸Œ ìš”ì•½ ì‹¤íŒ¨: {summary_result['error']}")
        
        summary = summary_result.get("script_summary")
        
        comment_count = summary_result.get("comment_count", 0)  # ëŒ“ê¸€ ìˆ˜ ë°˜í™˜(ê¸°ë³¸ê°’ 0)
        
        message = HumanMessage(content=f"ì˜ìƒ ìš”ì•½ ì™„ë£Œ. ëŒ“ê¸€ ìˆ˜: {comment_count}")
        return {
            "youtube_summary": summary, 
            "comment_count": comment_count,
            "messages": [message]
            }
    except Exception as e:
        return {"error": f"ìœ íŠœë¸Œ ìš”ì•½ ë…¸ë“œ ì˜¤ë¥˜: {e}"}
    
class ValidationResult(BaseModel):
    is_relevant: bool = Field(description="ìš”ì•½ ë‚´ìš©ì´ ê±´ê°•ì´ë‚˜ ìš´ë™ê³¼ ê´€ë ¨ì´ ìˆëŠ”ì§€ ì—¬ë¶€")
    reason: str = Field(description="ê´€ë ¨ì´ ìˆê±°ë‚˜ ì—†ëŠ”ì§€ì— ëŒ€í•œ ê°„ëµí•œ ì´ìœ ")

async def validate_summary_node(state: SupervisorGraphState) -> Dict[str, Any]:
    print("[Node 5-1] ì˜ìƒ ìš”ì•½ ê²€ì¦ ì¤‘...")
    if state.get("error"): return {}

    summary_dict = state.get("youtube_summary", {})
    summary_text = json.dumps(summary_dict)
    diagnosis_text = state["diagnosis"]["korean"]
    recommended_exercise = state["recommended_exercise"]["name"]
    search_query = state.get("search_query", "")  # ê²€ìƒ‰ì–´ ì¶”ê°€

    # ìš”ì•½ì´ ë„ˆë¬´ ì§§ê±°ë‚˜ ì—†ëŠ” ê²½ìš°, ë°”ë¡œ ë¶€ì í•© íŒì •
    if not summary_dict or len(summary_text) < 50:
        print("  > ê²€ì¦ ì‹¤íŒ¨: ìš”ì•½ ë‚´ìš©ì´ ë„ˆë¬´ ì§§ê±°ë‚˜ ì—†ìŠµë‹ˆë‹¤.")
        message = HumanMessage(content="ìš”ì•½ ê²€ì¦ ì‹¤íŒ¨: ë‚´ìš© ë¶€ì‹¤")
        return {"messages": [message]}

    # LLMì„ í†µí•œ ê´€ë ¨ì„± ê²€ì¦
    structured_validator = llm.with_structured_output(ValidationResult)
    prompt = f"""
ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ìì„¸ êµì •ì„ ìœ„í•œ ìš´ë™ ì˜ìƒì„ í•„í„°ë§í•˜ëŠ” AI ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

[ë¶„ì„í•  ì •ë³´]
- ìì„¸ ì§„ë‹¨: '{diagnosis_text}'
- ì¶”ì²œ ìš´ë™: '{recommended_exercise}'
- ìš´ë™ ê²€ìƒ‰ ê¸°ì¤€: '{search_query}'
- ì¶”ì²œ ìš´ë™ì˜ íš¨ê³¼: '{state["recommended_exercise"].get("description", "íš¨ê³¼ ì •ë³´ ì—†ìŒ")}'
- ì˜ìƒ ìš”ì•½: '{summary_text}'

[ìˆ˜í–‰í•  ì‘ì—…]
- 'ìì„¸ ì§„ë‹¨'ì„ ê°œì„ í•˜ê³  'ì¶”ì²œ ìš´ë™'ì„ ìˆ˜í–‰í•˜ëŠ” ë° 'ì˜ìƒ ìš”ì•½'ì˜ ë‚´ìš©ì´ ì í•©í•œì§€ íŒë‹¨í•´ì£¼ì„¸ìš”.
- 'ìš´ë™ ê²€ìƒ‰ ê¸°ì¤€'ì— ë§ëŠ” ì˜ìƒì¸ì§€ë„ í•¨ê»˜ ê²€í† í•´ì£¼ì„¸ìš”.
- ê°€ì¥ ë¨¼ì € ì œì™¸ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë‚´ìš©ì´ ìˆëŠ”ì§€ ì‚´í´ë³´ê³ , í•´ë‹¹í•  ì‹œ ë°˜ë“œì‹œ ê´€ë ¨ì—†ìŒìœ¼ë¡œ íŒë‹¨í•´ì•¼ í•©ë‹ˆë‹¤.
- ë˜í•œ ë™ì˜ìƒì˜ ë‚´ìš©ê³¼ 'ì¶”ì²œ ìš´ë™ì˜ íš¨ê³¼'ê°€ ì„œë¡œ ê´€ë ¨ìˆëŠ”ì§€ë„ íŒë‹¨í•´ì•¼ í•©ë‹ˆë‹¤.

[ì œì™¸ ì¡°ê±´]
- **ìŠ¤í¬ì¸  ì „ë¬¸ í›ˆë ¨:** íŠ¹ì • ìŠ¤í¬ì¸ (ì˜ˆ: ì¶•êµ¬, ì•¼êµ¬, ê³¨í”„, ìˆ˜ì˜)ì˜ ê¸°ìˆ  í–¥ìƒì„ ìœ„í•œ í›ˆë ¨ì€ 'ê´€ë ¨ ì—†ìŒ'ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
- **ê²€ìƒ‰ ê¸°ì¤€ ë¶ˆì¼ì¹˜:** ì˜ìƒ ë‚´ìš©ì´ 'ìš´ë™ ê²€ìƒ‰ ê¸°ì¤€'ê³¼ í¬ê²Œ ë‹¤ë¥¸ ê²½ìš° 'ê´€ë ¨ ì—†ìŒ'ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.

[ì¶œë ¥ í˜•ì‹]
ì•„ë˜ JSON í˜•ì‹ì— ë”°ë¼, íŒë‹¨ ê²°ê³¼(`is_relevant`)ì™€ êµ¬ì²´ì ì¸ ì´ìœ (`reason`)ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

{{
  "is_relevant": <true ë˜ëŠ” false>,
  "reason": "<íŒë‹¨ ì´ìœ ë¥¼ ê°„ë‹¨íˆ ì‘ì„±í•©ë‹ˆë‹¤.>"
}}
"""
    
    validation: ValidationResult = structured_validator.invoke(prompt)
    
    if validation.is_relevant:
        print(f"  > ê²€ì¦ ì„±ê³µ: {validation.reason}")
        message = HumanMessage(content="ìš”ì•½ ê²€ì¦ ì„±ê³µ")
    else:
        print(f"  > ê²€ì¦ ì‹¤íŒ¨: {validation.reason}")
        message = HumanMessage(content="ìš”ì•½ ê²€ì¦ ì‹¤íŒ¨: ê´€ë ¨ì„± ë¶€ì¡±")
        
    return {"messages": [message]}

async def ask_user_response_node(state: SupervisorGraphState) -> Dict[str, Any]:
    """ì‚¬ìš©ìì—ê²Œ ëŒ“ê¸€ ìš”ì•½ ê´€ì‹¬ ì—¬ë¶€ë¥¼ ë¬»ëŠ” ë…¸ë“œ"""
    print("[Node 5-2] ì‚¬ìš©ì ì‘ë‹µ ìš”ì²­ ì¤‘...")
    
    # ì½˜ì†”ì—ì„œ ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
    print("\n--- ì¶”ê°€ ì •ë³´ ì œê³µ ---")
    print("ì˜ìƒ ìŠ¤í¬ë¦½íŠ¸ ìš”ì•½ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print("ì˜ìƒì— ëŒ€í•œ ëŒ“ê¸€ ë°˜ì‘ë„ ê¶ê¸ˆí•˜ì‹œë‹¤ë©´ ì•Œë ¤ë“œë¦´ê²Œìš”!")
    
    user_input = input("ì‘ë‹µí•´ì£¼ì„¸ìš” (ì˜ˆ: 'ì‘', 'ë„¤', 'ë³´ì—¬ì¤˜' ë˜ëŠ” 'ê´œì°®ì•„', 'ì•„ë‹ˆ'): ").strip()
    
    message = HumanMessage(content=f"ì‚¬ìš©ì ì‘ë‹µ ìˆ˜ì§‘ ì™„ë£Œ: {user_input}")
    return {
        "user_response": user_input,
        "youtube_thread_id": f"thread_{hash(state['chatbot_result']['youtube_url'])}",
        "youtube_config": {"configurable": {"thread_id": f"thread_{hash(state['chatbot_result']['youtube_url'])}"}},
        "messages": [message]
    }
    
async def comment_summary_unavailable_node(state: SupervisorGraphState) -> Dict[str, Any]:
    """ëŒ“ê¸€ ìˆ˜ê°€ ì ì–´ ìš”ì•½ ì œê³µì´ ë¶ˆê°€ëŠ¥í•¨ì„ ì•Œë¦¬ëŠ” ë…¸ë“œ"""
    print("[Node 5-3] ëŒ“ê¸€ ìš”ì•½ ì œê³µ ë¶ˆê°€ ì•ˆë‚´")
    
    # ìµœì¢… ê²°ê³¼ì— í‘œì‹œë  ë©”ì‹œì§€ë¥¼ youtube_summaryì— ì¶”ê°€
    updated_youtube_summary = state.get("youtube_summary", {})
    if isinstance(updated_youtube_summary, dict):
         updated_youtube_summary["comment_summary"] = "ëŒ“ê¸€ ê°œìˆ˜ê°€ 10ê°œ ë¯¸ë§Œìœ¼ë¡œ ëŒ“ê¸€ ìš”ì•½ì„ ì œê³µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
    
    message = HumanMessage(content="ëŒ“ê¸€ ìš”ì•½ ì œê³µ ë¶ˆê°€: ëŒ“ê¸€ ìˆ˜ ë¶€ì¡±")
    return {
        "messages": [message],
        "youtube_summary": updated_youtube_summary
    }
    
async def rerun_youtube_agent_node(state: SupervisorGraphState) -> Dict[str, Any]:
    """ì‚¬ìš©ì ì‘ë‹µì„ ë°”íƒ•ìœ¼ë¡œ YouTube agentë¥¼ ì¬ì‹¤í–‰í•˜ëŠ” ë…¸ë“œ"""
    print("[Node 5-4] YouTube Agent ì¬ì‹¤í–‰ ì¤‘...")
    
    try:
        # YouTube agentì˜ ë©”ëª¨ë¦¬ ê·¸ë˜í”„ ì‚¬ìš©
        youtube_state = {
            "url": state["chatbot_result"]["youtube_url"],
            "reply": state["user_response"],
            "script_summary": state.get("youtube_summary", {})
        }
        
        # continue_with_memory í•¨ìˆ˜ ì‚¬ìš©í•˜ì—¬ ëŒ“ê¸€ ìš”ì•½ ì‹¤í–‰
        from app.agents.youtube_agent import graph_memory, continue_with_memory
        
        result = continue_with_memory(
            graph_memory, 
            youtube_state, 
            state["youtube_config"], 
            {"reply": state["user_response"], "url": youtube_state["url"]}
        )
        
        # ëŒ“ê¸€ ìš”ì•½ ê²°ê³¼ ì¶”ê°€
        updated_youtube_summary = state.get("youtube_summary", {})
        if result.get("comment_summary"):
            updated_youtube_summary["comment_summary"] = result["comment_summary"]
        
        message = HumanMessage(content="YouTube ëŒ“ê¸€ ìš”ì•½ ì™„ë£Œ")
        return {
            "youtube_summary": updated_youtube_summary,
            "messages": [message]
        }
        
    except Exception as e:
        message = HumanMessage(content=f"YouTube ì¬ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}")
        return {"messages": [message]}

async def present_final_result_node(state: SupervisorGraphState) -> Dict[str, Any]:
    print("âœ… ìµœì¢… ê²°ê³¼ ìƒì„± ì¤‘...")
    if state.get("error"):
        final_output = {"success": False, "error_message": state["error"]}
    else:
        final_output = {
            "success": True,
            "analysis": {
                "diagnosis": state.get("diagnosis", {}).get("korean"),
                "details": state.get("pose_analysis_result")
            },
            "primary_recommendation": state.get("recommended_exercise"), 
            "supplementary_video": { 
                "search_phrase": state.get("chatbot_result", {}).get("search_phrase"),
                "youtube_url": state.get("chatbot_result", {}).get("youtube_url"),
                "video_summary": state.get("youtube_summary") or {}
            },            
        }
    print("\n--- ìµœì¢… ê²°ê³¼ (JSON) ---")
    print(json.dumps(final_output, indent=2, ensure_ascii=False))
    return {"final_output": final_output}

# --- 4. Supervisor ë…¸ë“œ (ì¬ê²€ìƒ‰ ë¡œì§ ì¶”ê°€) ---
async def supervisor_node(state: SupervisorGraphState) -> Dict[str, str]:
    print("[Supervisor] ë‹¤ìŒ ì‘ì—… ê²°ì • ì¤‘...")
    last_message = state['messages'][-1].content
    
    if "ìì„¸ ë¶„ì„ ì™„ë£Œ" in last_message:
        return {"next_agent": "plot_radar_chart"}
    elif "ë ˆì´ë” ì°¨íŠ¸ ìƒì„± ì™„ë£Œ" in last_message:
        return {"next_agent": "recommend_exercise"}
    elif "DB ê¸°ë°˜ ìš´ë™ ì¶”ì²œ ì™„ë£Œ" in last_message:
        user_choice = input("ìš´ë™ ì¶”ì²œ í›„ ë‹¤ìŒ ë‹¨ê³„ ì„ íƒ (1: AI ì½”ì¹˜ì™€ ëŒ€í™”, 2: ìœ íŠœë¸Œ ì˜ìƒ ì¶”ì²œ): ").strip()
        if user_choice == "1":
            return {"next_agent": "ai_coach_interaction"}
        elif user_choice == "2":
            return {"next_agent": "video_search"}
        else:
            print("ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. ê¸°ë³¸ì ìœ¼ë¡œ ìœ íŠœë¸Œ ì˜ìƒ ì¶”ì²œìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
            return {"next_agent": "video_search"}
    elif "AI ì½”ì¹˜ ëŒ€í™” ì™„ë£Œ" in last_message:
        return {"next_agent": "present_final_result"}
    elif "ìœ íŠœë¸Œ ì˜ìƒ ì¶”ì²œ ì™„ë£Œ" in last_message:
        return {"next_agent": "summarize_video"}
    elif "ìœ íŠœë¸Œ ì˜ìƒ ê²€ìƒ‰ ì™„ë£Œ" in last_message:
        return {"next_agent": "summarize_video"}
    elif "ì˜ìƒ ìš”ì•½ ì™„ë£Œ" in last_message:
        return {"next_agent": "validate_summary"}
    elif "ìš”ì•½ ê²€ì¦ ì„±ê³µ" in last_message:
        # ê²€ì¦ ì„±ê³µ í›„ ëŒ“ê¸€ ìˆ˜ì— ë”°ë¼ ë¶„ê¸°
        comment_count = state.get("comment_count", 0)
        if comment_count >= 10:
            print(f"  > ëŒ“ê¸€ ìˆ˜({comment_count})ê°€ 10ê°œ ì´ìƒì´ë¯€ë¡œ ì‚¬ìš©ìì—ê²Œ ì§ˆë¬¸í•©ë‹ˆë‹¤.")
            return {"next_agent": "ask_user_response"}
        else:
            print(f"  > ëŒ“ê¸€ ìˆ˜({comment_count})ê°€ 10ê°œ ë¯¸ë§Œì´ë¯€ë¡œ ìš”ì•½ì„ ì œê³µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return {"next_agent": "comment_summary_unavailable"}
    elif "ì‚¬ìš©ì ì‘ë‹µ ìˆ˜ì§‘ ì™„ë£Œ" in last_message:
        # ì‚¬ìš©ì ì‘ë‹µì— ë”°ë¼ ë¶„ê¸°
        user_response = state.get("user_response", "").lower()
        
        # ê¸ì •ì  ì‘ë‹µì¸ì§€ í™•ì¸
        positive_responses = ["ì‘", "ë„¤", "ë³´ì—¬ì¤˜", "ê¶ê¸ˆí•´", "ê·¸ë˜", "ì¢‹ì•„", "yes", "y"]
        if any(pos in user_response for pos in positive_responses):
            return {"next_agent": "rerun_youtube_agent"}
        else:
            # ë¶€ì •ì  ì‘ë‹µì´ë©´ ë°”ë¡œ ìµœì¢… ê²°ê³¼ë¡œ
            return {"next_agent": "present_final_result"}
    elif "YouTube ëŒ“ê¸€ ìš”ì•½ ì™„ë£Œ" in last_message:
        return {"next_agent": "present_final_result"}
    elif "ëŒ“ê¸€ ìš”ì•½ ì œê³µ ë¶ˆê°€" in last_message: 
        return {"next_agent": "present_final_result"}
    elif "YouTube ì¬ì‹¤í–‰ ì‹¤íŒ¨" in last_message:
        return {"next_agent": "present_final_result"}
    elif "ìš”ì•½ ê²€ì¦ ì‹¤íŒ¨" in last_message:
        if state["search_retries"] >= 2:
            return {"next_agent": "present_final_result"}
        else:
            return {"next_agent": "video_search"}
    else:
        return {"next_agent": "END"}
    
    
# --- 5. ê·¸ë˜í”„ êµ¬ì„± (Supervisor íŒ¨í„´) ---
workflow = StateGraph(SupervisorGraphState)

workflow.add_node("analyze_user_pose", analyze_user_pose_node)
workflow.add_node("plot_radar_chart", plot_radar_chart_node)
workflow.add_node("recommend_exercise", recommend_exercise_node)
workflow.add_node("video_search", video_search_node)
workflow.add_node("summarize_video", summarize_video_node)
workflow.add_node("validate_summary", validate_summary_node)
workflow.add_node("present_final_result", present_final_result_node)
workflow.add_node("ask_user_response", ask_user_response_node)
workflow.add_node("rerun_youtube_agent", rerun_youtube_agent_node)
workflow.add_node("comment_summary_unavailable", comment_summary_unavailable_node)
workflow.add_node("supervisor", supervisor_node)
workflow.add_node("ai_coach_interaction", ai_coach_interaction_node)

workflow.set_entry_point("analyze_user_pose")
workflow.add_edge("analyze_user_pose", "supervisor")
workflow.add_edge("plot_radar_chart", "supervisor")
workflow.add_edge("recommend_exercise", "supervisor")
workflow.add_edge("video_search", "supervisor")
workflow.add_edge("summarize_video", "supervisor")
workflow.add_edge("validate_summary", "supervisor")
workflow.add_edge("ask_user_response", "supervisor")
workflow.add_edge("rerun_youtube_agent", "supervisor")
workflow.add_edge("comment_summary_unavailable", "supervisor")
workflow.add_edge("ai_coach_interaction", "supervisor")

workflow.add_conditional_edges(
    "supervisor",
    lambda state: state["next_agent"],
    {
        "plot_radar_chart": "plot_radar_chart",
        "recommend_exercise": "recommend_exercise",
        "video_search": "video_search",
        "summarize_video": "summarize_video",
        "validate_summary": "validate_summary",
        "ask_user_response": "ask_user_response",  
        "rerun_youtube_agent": "rerun_youtube_agent", 
        "comment_summary_unavailable": "comment_summary_unavailable",
        "present_final_result": "present_final_result",
        "END": END
    }
)
workflow.add_edge("present_final_result", END)
workflow_app = workflow.compile()  # LangGraph ì›Œí¬í”Œë¡œìš° ì¸ìŠ¤í„´ìŠ¤

# --- ë¶„ì„/ë ˆì´ë”ì°¨íŠ¸ë§Œ í¬í•¨í•˜ëŠ” ì›Œí¬í”Œë¡œìš° ì •ì˜ ---
analysis_workflow = StateGraph(SupervisorGraphState)
analysis_workflow.add_node("analyze_user_pose", analyze_user_pose_node)
analysis_workflow.add_node("plot_radar_chart", plot_radar_chart_node)
analysis_workflow.set_entry_point("analyze_user_pose")
analysis_workflow.add_edge("analyze_user_pose", "plot_radar_chart")
analysis_workflow.add_edge("plot_radar_chart", END)
analysis_workflow_app = analysis_workflow.compile()

# --- FastAPI ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ---
app = FastAPI()

@app.middleware("http")
async def log_requests(request: Request, call_next):
    print(f"=== Request Log ===")
    print(f"Method: {request.method}")
    print(f"URL: {request.url}")
    print(f"Headers: {dict(request.headers)}")
    
    if request.method == "POST":
        try:
            body = await request.body()
            print(f"Request body: {body.decode()}")
        except Exception as e:
            print(f"Error reading request body: {e}")
    
    response = await call_next(request)
    print(f"Response status: {response.status_code}")
    print(f"=== End Request Log ===")
    return response

class AnalysisRequest(BaseModel):
    image_url: str
    analysis_mode: str = "front"

# --- ë¶„ì„/ë ˆì´ë”ì°¨íŠ¸ë§Œ ì‹¤í–‰í•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸ ---
@app.post("/analyze-graph")
async def analyze_graph_endpoint(request: AnalysisRequest):
    print("==== /analyze-graph endpoint called ====")
    print(f"Received image_url: {request.image_url}, analysis_mode: {request.analysis_mode}")
    # 1. ë¶„ì„/ë ˆì´ë”ì°¨íŠ¸ë§Œ ì‹¤í–‰í•˜ëŠ” ì›Œí¬í”Œë¡œìš° ìƒíƒœ ì´ˆê¸°í™”
    initial_state = {
        "messages": [HumanMessage(content="ìì„¸ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.")],
        "image_path": request.image_url,
        "analysis_mode": request.analysis_mode,
        "search_retries": 0,
        "comment_count": 0,
        "user_response": None,
        "youtube_thread_id": None,
        "youtube_config": None,
        "radar_chart_path": None # ì´ˆê¸°í™”
    }
    # 2. ë¶„ì„/ë ˆì´ë”ì°¨íŠ¸ë§Œ ì‹¤í–‰
    result = analysis_workflow_app.invoke(initial_state)
    print("result keys:", result.keys())
    print("radar_chart_path in result:", result.get("radar_chart_path"))
    # 3. ë ˆì´ë” ì°¨íŠ¸ Cloudinary ì—…ë¡œë“œ
    radar_chart_path = result.get("radar_chart_path")
    print("ë ˆì´ë” ì°¨íŠ¸ ê²½ë¡œ:", radar_chart_path)
    radar_chart_url = None
    if radar_chart_path:
        try:
            upload_result = cloudinary.uploader.upload(radar_chart_path, folder="radar_charts/")
            radar_chart_url = upload_result["secure_url"]
            print("Cloudinary ì—…ë¡œë“œ ê²°ê³¼:", radar_chart_url)
        except Exception as e:
            print("Cloudinary ì—…ë¡œë“œ ì—ëŸ¬:", e)
    # 4. ë¶„ì„ ì ìˆ˜ ì¶”ì¶œ
    pose_data = result.get("pose_analysis_result", {})
    scores = pose_data.get("scores", {})
    feedback = pose_data.get("feedback", {})
    measurements = pose_data.get("measurements", {})
    return {
        "diagnosis": result.get("diagnosis", {}),  # ì „ì²´ diagnosis ê°ì²´ ë°˜í™˜ (korean í‚¤ í¬í•¨)
        "radar_chart_url": radar_chart_url,
        "spineCurvScore": scores.get("ì²™ì¶”êµ½ìŒscore"),
        "spineScolScore": scores.get("ì²™ì¶”íœ¨score"),
        "pelvicScore": scores.get("ê³¨ë°˜í‹€ì–´ì§score"),
        "neckScore": scores.get("ê±°ë¶ëª©score"),
        "shoulderScore": scores.get("ì–´ê¹¨score"),
        "feedback": feedback,
        "measurements": measurements
    }

class ChatbotRequest(BaseModel):
    type: str  # "ai_coach" or "recommend_video"
    userId: int  # user_idì—ì„œ userIdë¡œ ë³€ê²½
    historyId: int  # history_idì—ì„œ historyIdë¡œ ë³€ê²½
    message: Optional[str] = None

class ChatbotResponse(BaseModel):
    type: str
    response: str
    video_url: Optional[str] = None
    video_title: Optional[str] = None
    
    # camelCase ë³„ì¹­ ì¶”ê°€ (í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ì„±)
    videoUrl: Optional[str] = None
    videoTitle: Optional[str] = None
    
    def __init__(self, **data):
        super().__init__(**data)
        # snake_case ê°’ì„ camelCaseì—ë„ ì„¤ì •
        if self.video_url is not None:
            self.videoUrl = self.video_url
        if self.video_title is not None:
            self.videoTitle = self.video_title

def get_analysis_history_from_spring(history_id: int):
    SPRING_API_URL = "http://localhost:8081/api/analysis-histories"
    try:
        print(f"Spring API í˜¸ì¶œ: {SPRING_API_URL}/{history_id}")
        resp = requests.get(f"{SPRING_API_URL}/{history_id}")
        print(f"Spring API ì‘ë‹µ ìƒíƒœ: {resp.status_code}")
        
        if resp.status_code == 200:
            result = resp.json()
            print(f"Spring API ì‘ë‹µ ë°ì´í„°: {result}")
            return result
        else:
            print(f"Spring API ì—ëŸ¬ ì‘ë‹µ: {resp.text}")
            return None
    except requests.exceptions.ConnectionError as e:
        print(f"Spring Boot ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e}")
        print("Spring Boot ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return None
    except Exception as e:
        print(f"Spring API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        print(f"Exception type: {type(e)}")
        return None

@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    print(f"Global exception handler called: {exc}")
    print(f"Request path: {request.url}")
    print(f"Request method: {request.method}")
    print(f"Exception type: {type(exc)}")
    print(f"Exception details: {traceback.format_exc()}")
    
    return JSONResponse(
        status_code=500,
        content={"detail": f"Internal server error: {str(exc)}"}
    )

@app.post("/chatbot", response_model=ChatbotResponse)
async def chatbot_endpoint(req: ChatbotRequest):
    print(f"==== /chatbot endpoint called ====")
    print(f"Request data: {req}")
    print(f"Type: {req.type}, User ID: {req.userId}, History ID: {req.historyId}")
    print(f"Message: {req.message}")
    print(f"History ID type: {type(req.historyId)}")
    
    try:
        # 1. ë¶„ì„ ê²°ê³¼ Springì—ì„œ ì¡°íšŒ
        print(f"Spring APIì— ìš”ì²­í•  history_id: {req.historyId}")
        history = get_analysis_history_from_spring(req.historyId)
        if not history:
            print(f"ë¶„ì„ ì´ë ¥ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. history_id: {req.historyId}")
            raise HTTPException(status_code=404, detail="ë¶„ì„ ì´ë ¥ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # 2. diagnosis ë“± state êµ¬ì„±
        diagnosis = {}
        if history.get("diagnosis"):
            try:
                # JSON íŒŒì‹± ì‹œë„
                parsed_diagnosis = json.loads(history["diagnosis"])
                if isinstance(parsed_diagnosis, dict) and "korean" in parsed_diagnosis:
                    # korean í•„ë“œê°€ ìˆëŠ” ê°ì²´ì¸ ê²½ìš°
                    diagnosis = parsed_diagnosis
                elif isinstance(parsed_diagnosis, str):
                    # íŒŒì‹±ëœ ê²°ê³¼ê°€ ë¬¸ìì—´ì¸ ê²½ìš°
                    diagnosis = {"korean": parsed_diagnosis}
                else:
                    # ê¸°íƒ€ ê°ì²´ì¸ ê²½ìš°
                    diagnosis = {"korean": str(parsed_diagnosis)}
            except (json.JSONDecodeError, TypeError):
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë¬¸ìì—´ ì‚¬ìš©
                diagnosis = {"korean": history["diagnosis"]}
        else:
            diagnosis = {"korean": "ì§„ë‹¨ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."}

        print(f"Diagnosis: {diagnosis}")

        # 3. ì¶”ì²œ ìš´ë™ì„ recommend_exercise_nodeë¡œë¶€í„° ë°›ì•„ì˜´
        rec_state = {
            "diagnosis": diagnosis,
            "search_retries": 0,
            "tried_video_urls": [],
            "user_message": req.message  # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        }
        
        print("Running recommend_exercise_node...")
        rec_result = recommend_exercise_node(rec_state)
        
        if "error" in rec_result:
            print(f"Error in recommend_exercise_node: {rec_result['error']}")
            return ChatbotResponse(
                type="error", 
                response=f"ìš´ë™ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {rec_result['error']}"
            )
            
        recommended_exercise = rec_result.get("recommended_exercise", {"name": "ëª© ìŠ¤íŠ¸ë ˆì¹­"})
        search_query = rec_result.get("search_query", "")  # ìƒì„±ëœ ê²€ìƒ‰ì–´ ì¶”ì¶œ
        print(f"Recommended exercise: {recommended_exercise}")
        print(f"Generated search query: {search_query}")

        # 4. ê¸°ì¡´ ë…¸ë“œ í™œìš©
        if req.type == "ai_coach":
            print("Running ai_coach_interaction_node...")
            state = {
                "diagnosis": diagnosis,
                "recommended_exercise": recommended_exercise,
                "user_message": req.message,  # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
                "search_query": search_query  # ìƒì„±ëœ ê²€ìƒ‰ì–´ ì¶”ê°€
            }
            result = ai_coach_interaction_node(state)
            
            if "error" in result:
                print(f"Error in ai_coach_interaction_node: {result['error']}")
                return ChatbotResponse(
                    type="error", 
                    response=f"AI ì½”ì¹˜ ì‘ë‹µ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {result['error']}"
                )
                
            response_text = result["messages"][-1].content if "messages" in result and result["messages"] else "AI ì½”ì¹˜ ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤."
            print(f"AI Coach response: {response_text}")
            return ChatbotResponse(type="ai_coach", response=response_text)

        elif req.type == "recommend_video":
            print("Running video recommendation workflow...")
            state = {
                "diagnosis": diagnosis,  # diagnosis ì •ë³´ ì¶”ê°€
                "recommended_exercise": recommended_exercise,
                "search_retries": 0,
                "tried_video_urls": [],
                "user_message": req.message,  # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
                "search_query": search_query  # ìƒì„±ëœ ê²€ìƒ‰ì–´ ì¶”ê°€
            }
            
            # 1. ì˜ìƒ ì¶”ì²œ
            print("Running video_search_node...")
            result = await video_search_node(state)
            
            if "error" in result:
                print(f"Error in video_search_node: {result['error']}")
                return ChatbotResponse(
                    type="error", 
                    response=f"ì˜ìƒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {result['error']}"
                )
                
            chatbot_result = result.get("chatbot_result", {})
            print(f"chatbot_result from video_search_node: {chatbot_result}")
            
            video_url = chatbot_result.get("youtube_url")
            video_title = chatbot_result.get("video_title")
            
            print(f"Video URL: {video_url}")
            print(f"Video Title: {video_title}")
            
            if not video_url or "No video found" in str(video_url):
                return ChatbotResponse(
                    type="recommend_video",
                    response="ì¶”ì²œ ì˜ìƒì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.",
                    video_url=None,
                    video_title=None
                )
                
            # 2. ì˜ìƒ ìš”ì•½
            print("Running summarize_video_node...")
            state.update({"chatbot_result": chatbot_result})
            result = await summarize_video_node(state)
            
            if "error" in result:
                print(f"Error in summarize_video_node: {result['error']}")
                # ìš”ì•½ ì‹¤íŒ¨í•´ë„ ì˜ìƒì€ ë°˜í™˜
                return ChatbotResponse(
                    type="recommend_video",
                    response="ì˜ìƒì„ ì°¾ì•˜ì§€ë§Œ ìš”ì•½ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì˜ìƒì€ í™•ì¸í•´ë³´ì„¸ìš”.",
                    video_url=video_url,
                    video_title=video_title
                )
                
            summary = result.get("youtube_summary")
            comment_count = result.get("comment_count", 0)
            
            # 3. ìš”ì•½ ê²€ì¦
            print("Running validate_summary_node...")
            state.update({"youtube_summary": summary, "comment_count": comment_count})
            result = await validate_summary_node(state)
            
            # 4. ì˜ìƒ ìš”ì•½ ë‚´ìš©ì„ ì‘ë‹µì— í¬í•¨
            print(f"Final response - Video URL: {video_url}, Video Title: {video_title}")
            
            # ì˜ìƒ ìš”ì•½ ë‚´ìš© ì¶”ì¶œ
            summary_text = ""
            if summary:
                if isinstance(summary, dict):
                    # ìš”ì•½ì´ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° ì£¼ìš” ë‚´ìš© ì¶”ì¶œ
                    if "summary" in summary:
                        summary_text = summary["summary"]
                    elif "content" in summary:
                        summary_text = summary["content"]
                    else:
                        summary_text = str(summary)
                else:
                    summary_text = str(summary)
            
            # ì‘ë‹µ ë©”ì‹œì§€ êµ¬ì„±
            response_message = f"ğŸ“º ì˜ìƒ ìš”ì•½\n\n{summary_text}\n\n"
            
            if comment_count >= 10:
                print(f"Comment count: {comment_count} - suggesting comment summary")
                response_message += "ğŸ“Š ëŒ“ê¸€ ìš”ì•½ì„ ì›í•˜ì‹œë©´ ì•„ë˜ ë²„íŠ¼ì„ í´ë¦­í•´ì£¼ì„¸ìš”."
            else:
                print(f"Comment count: {comment_count} - comment summary unavailable")
                response_message += "ğŸ’¡ ëŒ“ê¸€ ìˆ˜ê°€ ì ì–´ ëŒ“ê¸€ ìš”ì•½ì„ ì œê³µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
            
            return ChatbotResponse(
                type="recommend_video",
                response=response_message,
                video_url=video_url,
                video_title=video_title
            )
        else:
            return ChatbotResponse(type="error", response="ì§€ì›í•˜ì§€ ì•ŠëŠ” typeì…ë‹ˆë‹¤.")
            
    except HTTPException:
        raise
    except Exception as e:
        print(f"Unexpected error in chatbot endpoint: {e}")
        print(f"Exception traceback: {traceback.format_exc()}")
        return ChatbotResponse(
            type="error", 
            response=f"ì±—ë´‡ ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )

@app.post("/chatbot/comment-summary", response_model=ChatbotResponse)
async def comment_summary_endpoint(req: ChatbotRequest):
    print(f"==== /chatbot/comment-summary endpoint called ====")
    print(f"Request data: {req}")
    
    try:
        # 1. ë¶„ì„ ê²°ê³¼ Springì—ì„œ ì¡°íšŒ
        history = get_analysis_history_from_spring(req.historyId)
        if not history:
            raise HTTPException(status_code=404, detail="ë¶„ì„ ì´ë ¥ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # 2. diagnosis ë“± state êµ¬ì„±
        diagnosis = {}
        if history.get("diagnosis"):
            try:
                parsed_diagnosis = json.loads(history["diagnosis"])
                if isinstance(parsed_diagnosis, dict) and "korean" in parsed_diagnosis:
                    diagnosis = parsed_diagnosis
                elif isinstance(parsed_diagnosis, str):
                    diagnosis = {"korean": parsed_diagnosis}
                else:
                    diagnosis = {"korean": str(parsed_diagnosis)}
            except (json.JSONDecodeError, TypeError):
                diagnosis = {"korean": history["diagnosis"]}
        else:
            diagnosis = {"korean": "ì§„ë‹¨ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."}

        # 3. ì‚¬ìš©ì ë©”ì‹œì§€ì—ì„œ YouTube URL ì¶”ì¶œ
        user_message = req.message or ""
        youtube_url_match = re.search(r'https://www\.youtube\.com/watch\?v=([\w-]+)', user_message)
        
        if not youtube_url_match:
            return ChatbotResponse(
                type="error",
                response="YouTube URLì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜ìƒ ë§í¬ë¥¼ í¬í•¨í•´ì„œ ìš”ì²­í•´ì£¼ì„¸ìš”."
            )
        
        video_id = youtube_url_match.group(1)
        youtube_url = f"https://www.youtube.com/watch?v={video_id}"
        
        print(f"ëŒ“ê¸€ ìš”ì•½ ìš”ì²­ - Video ID: {video_id}")
        
        # 4. YouTube ëŒ“ê¸€ ìš”ì•½ ì‹¤í–‰
        try:
            # ëŒ“ê¸€ ìš”ì•½ì„ ìœ„í•´ reply í•„ë“œë¥¼ ì„¤ì •
            summary_result = youtube_summary_agent.invoke({
                "url": youtube_url,
                "reply": "ëŒ“ê¸€ ìš”ì•½í•´ì£¼ì„¸ìš”"
            })
            
            if summary_result.get("error"):
                return ChatbotResponse(
                    type="error",
                    response=f"ëŒ“ê¸€ ìš”ì•½ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {summary_result['error']}"
                )
            
            comment_summary = summary_result.get("comment_summary", {})
            comment_count = summary_result.get("total_comment_count", 0)
            
            # ëŒ“ê¸€ ìš”ì•½ ë‚´ìš©ì„ í¬ë§·íŒ…
            if isinstance(comment_summary, dict):
                # CommentSummary ê°ì²´ì¸ ê²½ìš°
                overall_sentiment = comment_summary.get("overall_sentiment", {})
                key_topics = comment_summary.get("key_topics", [])
                user_tips = comment_summary.get("user_tips", [])
                faq = comment_summary.get("faq", [])
                
                response_text = f"ğŸ“Š ëŒ“ê¸€ ë¶„ì„ ê²°ê³¼\n\n"
                response_text += f"ğŸ’­ ì „ë°˜ì ì¸ ë¶„ìœ„ê¸°: {overall_sentiment.get('description', 'ë¶„ì„ ë¶ˆê°€')}\n"
                response_text += f"ğŸ“ˆ ê¸ì • ë°˜ì‘ ë¹„ìœ¨: {overall_sentiment.get('positive_percentage', 0)}%\n\n"
                
                if key_topics:
                    response_text += "ğŸ”¥ í•µì‹¬ ì£¼ì œ:\n"
                    for topic in key_topics:
                        response_text += f"â€¢ {topic}\n"
                    response_text += "\n"
                
                if user_tips:
                    response_text += "ğŸ’¡ ìœ ìš©í•œ íŒ:\n"
                    for tip in user_tips:
                        response_text += f"â€¢ {tip}\n"
                    response_text += "\n"
                
                if faq:
                    response_text += "â“ ìì£¼ ë¬»ëŠ” ì§ˆë¬¸:\n"
                    for q in faq:
                        response_text += f"â€¢ {q}\n"
            else:
                # ë¬¸ìì—´ì¸ ê²½ìš°
                response_text = f"ğŸ“Š ëŒ“ê¸€ ë¶„ì„ ê²°ê³¼\n\n{comment_summary}"
            
            return ChatbotResponse(
                type="comment_summary",
                response=response_text,
                video_url=youtube_url
            )
            
        except Exception as e:
            print(f"YouTube ëŒ“ê¸€ ìš”ì•½ ì˜¤ë¥˜: {e}")
            return ChatbotResponse(
                type="error",
                response=f"ëŒ“ê¸€ ìš”ì•½ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            )
            
    except HTTPException:
        raise
    except Exception as e:
        print(f"Unexpected error in comment summary endpoint: {e}")
        return ChatbotResponse(
            type="error",
            response=f"ëŒ“ê¸€ ìš”ì•½ ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )
