# app/graph/edges.py
import pandas as pd
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

from .state import ExerciseState
from config import LLM_MODEL_NAME

# LLM ëª¨ë¸ ì´ˆê¸°í™”
llm = ChatOpenAI(model=LLM_MODEL_NAME, temperature=0)

def check_goal_completion_edge(state: ExerciseState) -> str:
    """
    LLMì„ ì´ìš©í•´ ëª©í‘œ ë‹¬ì„± ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ì—¬ ë‹¤ìŒ ë…¸ë“œë¥¼ ê²°ì •í•©ë‹ˆë‹¤.
    'goal_achieved' ë˜ëŠ” 'goal_not_achieved'ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    print("--- [Edge 7] ëª©í‘œ ë‹¬ì„± ì—¬ë¶€ í™•ì¸ ---")
    
    if not state.get("final_goals") or not state.get("exercise_history"):
        print("... ëª©í‘œ ë˜ëŠ” ìš´ë™ ê¸°ë¡ì´ ì—†ì–´ íŒë‹¨ ë¶ˆê°€. ì›Œí¬í”Œë¡œìš°ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return "goal_not_achieved"

    print("ğŸ§  LLMìœ¼ë¡œ ëª©í‘œ ë‹¬ì„± ì—¬ë¶€ë¥¼ ì—„ê²©í•˜ê²Œ íŒë‹¨í•©ë‹ˆë‹¤...")
    history_str = pd.DataFrame(state['exercise_history']).to_string()

    eval_prompt = ChatPromptTemplate.from_messages([
        ("system", "ë‹¹ì‹ ì€ ì—„ê²©í•œ ì‹¬íŒì…ë‹ˆë‹¤. 'ë‹¬ì„± ëª©í‘œ'ì™€ 'ìš´ë™ ê¸°ë¡'ì„ ë¹„êµí•˜ì—¬ ëª©í‘œ ë‹¬ì„± ì—¬ë¶€ë¥¼ íŒë‹¨í•´ì£¼ì„¸ìš”. ë‹µë³€ì€ ì˜¤ì§ 'goal_achieved' ë˜ëŠ” 'goal_not_achieved' ë‘˜ ì¤‘ í•˜ë‚˜ë¡œë§Œ í•´ì•¼ í•©ë‹ˆë‹¤."),
        ("human", "ë‹¬ì„± ëª©í‘œ (JSON):\n{final_goals}\n\nìš´ë™ ê¸°ë¡:\n{history}\n\níŒë‹¨ ê²°ê³¼ëŠ” ë¬´ì—‡ì…ë‹ˆê¹Œ?")
    ])
    
    eval_chain = eval_prompt | llm
    result = eval_chain.invoke({
        "final_goals": state['final_goals'],
        "history": history_str
    })
    
    decision = result.content.strip()
    
    if "goal_achieved" in decision:
        print("íŒë‹¨ ê²°ê³¼: ğŸ‰ ëª©í‘œ ë‹¬ì„±! 'ë³´ìƒ ì œê³µ' ë…¸ë“œë¡œ ì´ë™í•©ë‹ˆë‹¤.")
        return "goal_achieved"
    else:
        print("íŒë‹¨ ê²°ê³¼: ğŸ’ª ëª©í‘œ ë¯¸ë‹¬ì„±. ì›Œí¬í”Œë¡œìš°ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return "goal_not_achieved"